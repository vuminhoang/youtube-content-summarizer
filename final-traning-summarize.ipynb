{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7978482,"sourceType":"datasetVersion","datasetId":4695577},{"sourceId":8394271,"sourceType":"datasetVersion","datasetId":4993669}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-14T16:11:56.484700Z","iopub.execute_input":"2024-05-14T16:11:56.484961Z","iopub.status.idle":"2024-05-14T16:11:56.765168Z","shell.execute_reply.started":"2024-05-14T16:11:56.484938Z","shell.execute_reply":"2024-05-14T16:11:56.764193Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4e9bace67104ea0a107cdf9f72c4c43"}},"metadata":{}}]},{"cell_type":"code","source":"%%capture\n!pip install datasets\n!pip install transformers==4.17 sentencepiece\n!pip install rouge_score\n!pip install transformers[torch]\n!pip install accelerate -U\n!pip install evaluate\n!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2024-05-14T16:12:26.032649Z","iopub.execute_input":"2024-05-14T16:12:26.033342Z","iopub.status.idle":"2024-05-14T16:14:05.769581Z","shell.execute_reply.started":"2024-05-14T16:12:26.033309Z","shell.execute_reply":"2024-05-14T16:14:05.768243Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2024-05-14T16:14:05.771678Z","iopub.execute_input":"2024-05-14T16:14:05.772001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\nimport json\nimport os\nimport pandas as pd\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:39:30.189907Z","iopub.execute_input":"2024-05-13T10:39:30.190132Z","iopub.status.idle":"2024-05-13T10:39:31.297262Z","shell.execute_reply.started":"2024-05-13T10:39:30.190113Z","shell.execute_reply":"2024-05-13T10:39:31.296507Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, TrainingArguments\n\ntokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"minnehwg/finetune-newwiki-summarization-ver1\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:42:24.881171Z","iopub.execute_input":"2024-05-13T10:42:24.881558Z","iopub.status.idle":"2024-05-13T10:42:47.203256Z","shell.execute_reply.started":"2024-05-13T10:42:24.881528Z","shell.execute_reply":"2024-05-13T10:42:47.202427Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/741 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9826690ed15044489c3ef8d7d9902e11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/862M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e80ecec46c9e45a285bf54ae94575849"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Read and pre-processing the data","metadata":{}},{"cell_type":"code","source":"file_path = '/kaggle/input/newwiki-pandas/data.pkl'\ndf = pd.read_pickle(file_path)\n\nfrom datasets import Dataset\ndataset = Dataset.from_pandas(df)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:42:47.205575Z","iopub.execute_input":"2024-05-13T10:42:47.206277Z","iopub.status.idle":"2024-05-13T10:42:48.048722Z","shell.execute_reply.started":"2024-05-13T10:42:47.206242Z","shell.execute_reply":"2024-05-13T10:42:48.047713Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dataset[2]","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:42:48.049905Z","iopub.execute_input":"2024-05-13T10:42:48.050166Z","iopub.status.idle":"2024-05-13T10:42:48.668981Z","shell.execute_reply.started":"2024-05-13T10:42:48.050144Z","shell.execute_reply":"2024-05-13T10:42:48.667718Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'inputs': 'Một số loại hình dán có keo dính ở đằng sau, số khác chỉ có một miếng vải bên dưới. Xem xét kỹ hình dán và xác định xem bạn có cần thêm vật liệu gì không. Những hình dán thêu trang trí thường dày, cứng và có một lớp keo nhựa ở mặt dưới. Loại này có thể dùng để che giấu phần vải bị rách hoặc mất màu. Hình dán truyền nhiệt có hình in trên một mặt giấy, và mặt kia là loại giấy không bóng. Loại này không thể vá được chỗ rách, và phần vải bên dưới thường bị lộ rõ nếu không phải là vải trắng. Hình dán có mặt sau chỉ là chất liệu vải có thể gắn bằng vải keo ép. Các hình dán dùng để vá các lỗ thủng hoặc vết ố bẩn được thiết kế để hòa lẫn với vải thường có một lớp giấy đằng sau và cần được gỡ ra trước khi dán. Cân nhắc tự thiết kế hình dán nếu bạn không tìm được mẫu yêu thích. Các chất liệu như denim và cotton thường làm nền rất tốt cho các hình dán bằng bàn là. Nguyên tắc chung là chất liệu vải ít nhất phải dày bằng hình dán. Xem nhãn hướng dẫn cách chăm sóc quần áo để biết chất liệu vải có là được không nếu không được là, bạn sẽ thấy hình chiếc bàn là bị gạch chéo . Nếu trên quần áo không có nhãn hướng dẫn, bạn hãy cố đoán thử xem đó là chất liệu gì. Thật cẩn thận với loại vải polyester, vì việc sử dụng nhiệt độ cao khi là hình dán có thể làm cháy vải hoặc làm mất màu vải. Lụa và các chất liệu mỏng manh khác không phải là đối tượng thích hợp để dán hình bằng bàn là. Trước khi làm nóng bàn là, bạn hãy trải áo, dải băng đeo chéo hoặc ba lô của bạn lên bàn và xác định chính xác vị trí muốn đặt hình dán. Nếu chỉ định dán một hình duy nhất, bạn nên đặt ở vị trí đẹp và nổi bật sao cho hình dán có vẻ như được thiết kế để đặt ở đó. Nếu định dán thêm nhiều hình dán khác, chẳng hạn như muốn trang trí dải băng đeo chéo của các cô gái hoặc bất kỳ các món đồ nào khác, bạn cần tính trước để đảm bảo có đủ chỗ cho các hình dán. Nếu sử dụng hình dán giấy tự in, bạn phải nhớ là mọi hình không đối xứng sẽ được in ngược.',\n 'labels': 'Xác định loại hình dán trước khi sử dụng, bao gồm keo dính, vải keo ép hoặc giấy. Loại vải và hướng dẫn giặt là có thể ảnh hưởng đến phương pháp gắn hình dán.'}"},"metadata":{}}]},{"cell_type":"code","source":"# import re\n\n# def clean_text(example):\n# #     example['inputs'] = re.sub(r'[^a-zA-Z0-9\\s.,!?;:]', ' ', example['inputs'])\n# #     example['labels'] = re.sub(r'[^a-zA-Z0-9\\s.,!?;:]', ' ', example['labels'])\n#     example['inputs'] = re.sub(r'\\s+', ' ', example['inputs']).strip()\n#     example['labels'] = re.sub(r'\\s+', ' ', example['labels']).strip()\n#     return example\n\nimport unicodedata\n\ndef clean_text(example):\n    # Loại bỏ các ký tự không mong muốn từ chuỗi inputs và labels\n    example['inputs'] = remove_unwanted_chars(example['inputs'])\n    example['labels'] = remove_unwanted_chars(example['labels'])\n    \n    # Xóa khoảng trắng dư thừa trong inputs và labels, và loại bỏ khoảng trắng ở đầu và cuối chuỗi\n    example['inputs'] = ' '.join(example['inputs'].split())\n    example['labels'] = ' '.join(example['labels'].split())\n    \n    return example\n\ndef remove_unwanted_chars(text):\n    cleaned_text = []\n    for char in text:\n        # Kiểm tra xem ký tự có phải là ký tự chữ cái, chữ số, hoặc dấu cụ nhất định không\n        category = unicodedata.category(char)\n#         or category.startswith('P')\n        if char.isalnum() or char in [' ', '.','!', '?', ';', ':']:\n            cleaned_text.append(char)\n    return ''.join(cleaned_text)\n\n\ndef preprocess_function(examples):\n    model_inputs = tokenizer(\n        examples[\"inputs\"], max_length=1024, truncation=True, padding=True\n    )\n\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            examples[\"labels\"], max_length=256, truncation=True, padding=True\n        )\n    model_inputs['labels'] = labels['input_ids']\n    model_inputs['input_ids'] = model_inputs['input_ids']\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:42:48.670099Z","iopub.execute_input":"2024-05-13T10:42:48.670379Z","iopub.status.idle":"2024-05-13T10:42:48.763390Z","shell.execute_reply.started":"2024-05-13T10:42:48.670356Z","shell.execute_reply":"2024-05-13T10:42:48.762328Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(clean_text)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:42:48.766938Z","iopub.execute_input":"2024-05-13T10:42:48.767579Z","iopub.status.idle":"2024-05-13T10:43:01.658322Z","shell.execute_reply.started":"2024-05-13T10:42:48.767549Z","shell.execute_reply":"2024-05-13T10:43:01.657396Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9898 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"511e46c2860a4212a30e5082edfe2dc8"}},"metadata":{}}]},{"cell_type":"code","source":"dataset[2]","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:01.659910Z","iopub.execute_input":"2024-05-13T10:43:01.660265Z","iopub.status.idle":"2024-05-13T10:43:01.666493Z","shell.execute_reply.started":"2024-05-13T10:43:01.660232Z","shell.execute_reply":"2024-05-13T10:43:01.665692Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'inputs': 'Một số loại hình dán có keo dính ở đằng sau số khác chỉ có một miếng vải bên dưới. Xem xét kỹ hình dán và xác định xem bạn có cần thêm vật liệu gì không. Những hình dán thêu trang trí thường dày cứng và có một lớp keo nhựa ở mặt dưới. Loại này có thể dùng để che giấu phần vải bị rách hoặc mất màu. Hình dán truyền nhiệt có hình in trên một mặt giấy và mặt kia là loại giấy không bóng. Loại này không thể vá được chỗ rách và phần vải bên dưới thường bị lộ rõ nếu không phải là vải trắng. Hình dán có mặt sau chỉ là chất liệu vải có thể gắn bằng vải keo ép. Các hình dán dùng để vá các lỗ thủng hoặc vết ố bẩn được thiết kế để hòa lẫn với vải thường có một lớp giấy đằng sau và cần được gỡ ra trước khi dán. Cân nhắc tự thiết kế hình dán nếu bạn không tìm được mẫu yêu thích. Các chất liệu như denim và cotton thường làm nền rất tốt cho các hình dán bằng bàn là. Nguyên tắc chung là chất liệu vải ít nhất phải dày bằng hình dán. Xem nhãn hướng dẫn cách chăm sóc quần áo để biết chất liệu vải có là được không nếu không được là bạn sẽ thấy hình chiếc bàn là bị gạch chéo . Nếu trên quần áo không có nhãn hướng dẫn bạn hãy cố đoán thử xem đó là chất liệu gì. Thật cẩn thận với loại vải polyester vì việc sử dụng nhiệt độ cao khi là hình dán có thể làm cháy vải hoặc làm mất màu vải. Lụa và các chất liệu mỏng manh khác không phải là đối tượng thích hợp để dán hình bằng bàn là. Trước khi làm nóng bàn là bạn hãy trải áo dải băng đeo chéo hoặc ba lô của bạn lên bàn và xác định chính xác vị trí muốn đặt hình dán. Nếu chỉ định dán một hình duy nhất bạn nên đặt ở vị trí đẹp và nổi bật sao cho hình dán có vẻ như được thiết kế để đặt ở đó. Nếu định dán thêm nhiều hình dán khác chẳng hạn như muốn trang trí dải băng đeo chéo của các cô gái hoặc bất kỳ các món đồ nào khác bạn cần tính trước để đảm bảo có đủ chỗ cho các hình dán. Nếu sử dụng hình dán giấy tự in bạn phải nhớ là mọi hình không đối xứng sẽ được in ngược.',\n 'labels': 'Xác định loại hình dán trước khi sử dụng bao gồm keo dính vải keo ép hoặc giấy. Loại vải và hướng dẫn giặt là có thể ảnh hưởng đến phương pháp gắn hình dán.'}"},"metadata":{}}]},{"cell_type":"code","source":"\ntokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:01.667679Z","iopub.execute_input":"2024-05-13T10:43:01.668011Z","iopub.status.idle":"2024-05-13T10:43:10.547321Z","shell.execute_reply.started":"2024-05-13T10:43:01.667986Z","shell.execute_reply":"2024-05-13T10:43:10.546360Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=8):   0%|          | 0/9898 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67d24695428540ee83ccc563998a7134"}},"metadata":{}}]},{"cell_type":"code","source":"train_size = int(len(tokenized_dataset) * 0.8)\ntrain_dataset = tokenized_dataset.select(range(train_size))\nval_dataset = tokenized_dataset.select(range(train_size, len(dataset)))","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:10.548826Z","iopub.execute_input":"2024-05-13T10:43:10.549114Z","iopub.status.idle":"2024-05-13T10:43:10.558891Z","shell.execute_reply.started":"2024-05-13T10:43:10.549087Z","shell.execute_reply":"2024-05-13T10:43:10.558156Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"dataset[1]","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:10.559954Z","iopub.execute_input":"2024-05-13T10:43:10.560209Z","iopub.status.idle":"2024-05-13T10:43:10.575367Z","shell.execute_reply.started":"2024-05-13T10:43:10.560187Z","shell.execute_reply":"2024-05-13T10:43:10.574607Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'inputs': 'Hydroquinone là loại kem tẩy trắng hiệu quả có thể giúp giảm đáng kể sự xuất hiện của đồi mồi. Hydroquinone có bán ở nồng độ lên đến 2 ở dạng không kê đơn còn nồng độ cao hơn cần có đơn thuốc của bác sĩ. Cần biết rằng hydroquinone bị cấm ở nhiều quốc gia châu Âu và châu Á do đặc tính gây ung thư tiềm ẩn. Tuy nhiên ở một số quốc gia như Mỹ hydroquinone vẫn được bán rộng rãi. RetinA là sản phẩm chăm sóc da chống lão hóa tuyệt vời được dùng để chống lại nếp nhăn cải thiện độ trơn láng của da làm mờ vùng da không đều màu và tổn thương do ánh nắng bao gồm đốm đồi mồi. RetinA là dẫn xuất của vitamin A có sẵn ở dạng gel hoặc kem với nhiều nồng độ khác nhau. RetinA chỉ có sẵn ở dạng kê đơn nên bạn cần đi bác sĩ khám trước khi bắt đầu sử dụng. RetinA giúp loại bỏ đốm đồi mồi bằng cách tẩy da chết loại bỏ lớp da tăng sắc tố bên ngoài và để lộ lớp da mới tinh khôi bên dưới. Sự kết hợp của hai thành phần này đã được chứng minh là sẽ giúp làm sáng màu các vết đồi mồi. Hãy trao đổi với bác sĩ da liễu để được tư vấn hoặc kiểm tra nhãn sản phẩm để tìm loại có chứa cả hai thành phần này. Bạn có thể tìm thấy kem hoặc sữa dưỡng da có chứa cả hai thành phần này. Kem chống nắng không thực sự giúp giảm sự xuất hiện của đốm đồi mồi cũ nhưng sẽ ngăn đốm mới hình thành vì đồi mồi chủ yếu là do tổn thương bởi ánh nắng . Bên cạnh đó kem chống nắng sẽ ngăn đốm đồi mồi cũ trở nên đậm màu hơn hay dễ gây chú ý hơn. Nên thoa kem chống nắng chứa kẽm oxit và có chỉ số SPF ít nhất 15 hàng ngày ngay cả khi trời không nắng nóng.',\n 'labels': 'Hydroquinone và RetinA hiệu quả trong việc giảm đốm đồi mồi kết hợp 2 thành phần này cho kết quả tối ưu. Sử dụng kem chống nắng hằng ngày để ngăn ngừa đốm đồi mồi mới và làm mờ đốm cũ.'}"},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:10.576701Z","iopub.execute_input":"2024-05-13T10:43:10.577030Z","iopub.status.idle":"2024-05-13T10:43:10.583035Z","shell.execute_reply.started":"2024-05-13T10:43:10.576992Z","shell.execute_reply":"2024-05-13T10:43:10.582268Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"del tokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:10.583973Z","iopub.execute_input":"2024-05-13T10:43:10.584290Z","iopub.status.idle":"2024-05-13T10:43:10.593083Z","shell.execute_reply.started":"2024-05-13T10:43:10.584261Z","shell.execute_reply":"2024-05-13T10:43:10.592327Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:10.594100Z","iopub.execute_input":"2024-05-13T10:43:10.594353Z","iopub.status.idle":"2024-05-13T10:43:10.605066Z","shell.execute_reply.started":"2024-05-13T10:43:10.594332Z","shell.execute_reply":"2024-05-13T10:43:10.604200Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['labels', 'input_ids', 'attention_mask'],\n    num_rows: 7918\n})"},"metadata":{}}]},{"cell_type":"code","source":"val_dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:10.606125Z","iopub.execute_input":"2024-05-13T10:43:10.606443Z","iopub.status.idle":"2024-05-13T10:43:10.615204Z","shell.execute_reply.started":"2024-05-13T10:43:10.606412Z","shell.execute_reply":"2024-05-13T10:43:10.614421Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['labels', 'input_ids', 'attention_mask'],\n    num_rows: 1980\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## import metric","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport nltk\nnltk.download(\"punkt\")\nfrom nltk.tokenize import sent_tokenize\nimport evaluate\nrouge_score = evaluate.load(\"rouge\")\nfrom datasets import load_metric\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n    rouge_metric = load_metric('rouge')\n\n    rouge_metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n    rouge_scores = rouge_metric.compute()\n\n    return {k: v.mid.fmeasure * 100 for k, v in rouge_scores.items()}","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:10.618234Z","iopub.execute_input":"2024-05-13T10:43:10.618511Z","iopub.status.idle":"2024-05-13T10:43:13.383282Z","shell.execute_reply.started":"2024-05-13T10:43:10.618490Z","shell.execute_reply":"2024-05-13T10:43:13.382334Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96662062594d41fdaaa96f38fbe3dcfe"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Define traing args ","metadata":{}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\nfrom transformers import EarlyStoppingCallback\n\n        \ntraining_args = Seq2SeqTrainingArguments(\"finetune-newwiki-summarization-ver2\",\n                                      num_train_epochs=7,\n                                      learning_rate=1e-6,\n                                      warmup_ratio=0.1,\n                                      weight_decay=0.01,\n                                      per_device_train_batch_size=4,\n                                      per_device_eval_batch_size=4,\n                                      group_by_length=True,\n                                      save_strategy=\"epoch\",\n                                      evaluation_strategy=\"epoch\",\n                                      save_total_limit=1,\n                                      fp16=True, # if GPU\n                                      predict_with_generate=True,\n#                                       logging_steps=200,\n                                      push_to_hub=True,\n                                         load_best_model_at_end=True\n                                      )","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:13.384285Z","iopub.execute_input":"2024-05-13T10:43:13.384554Z","iopub.status.idle":"2024-05-13T10:43:13.474715Z","shell.execute_reply.started":"2024-05-13T10:43:13.384531Z","shell.execute_reply":"2024-05-13T10:43:13.473684Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Traning loop","metadata":{}},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:13.475908Z","iopub.execute_input":"2024-05-13T10:43:13.476199Z","iopub.status.idle":"2024-05-13T12:48:17.310319Z","shell.execute_reply.started":"2024-05-13T10:43:13.476173Z","shell.execute_reply":"2024-05-13T12:48:17.309299Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\nFor more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n  warnings.warn(warning_message, FutureWarning)\nCloning https://huggingface.co/minnehwg/finetune-newwiki-summarization-ver2 into local empty directory.\nUsing amp half precision backend\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n***** Running training *****\n  Num examples = 7918\n  Num Epochs = 7\n  Instantaneous batch size per device = 4\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 6930\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4950' max='6930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4950/6930 2:04:42 < 49:54, 0.66 it/s, Epoch 5/7]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.491200</td>\n      <td>0.470079</td>\n      <td>48.175356</td>\n      <td>25.022139</td>\n      <td>34.761329</td>\n      <td>37.073443</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.474800</td>\n      <td>0.469357</td>\n      <td>48.362864</td>\n      <td>25.364867</td>\n      <td>35.023890</td>\n      <td>37.308376</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.475500</td>\n      <td>0.469549</td>\n      <td>48.276979</td>\n      <td>25.190664</td>\n      <td>34.845579</td>\n      <td>37.193011</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.470300</td>\n      <td>0.469566</td>\n      <td>48.180064</td>\n      <td>25.176948</td>\n      <td>34.800357</td>\n      <td>37.081658</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.468000</td>\n      <td>0.469694</td>\n      <td>48.165870</td>\n      <td>25.149090</td>\n      <td>34.779352</td>\n      <td>37.089311</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 1980\n  Batch size = 8\n/tmp/ipykernel_34/806200219.py:17: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n  rouge_metric = load_metric('rouge')\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"767746d78a1841ae8131aff44f0a625b"}},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to finetune-newwiki-summarization-ver2/checkpoint-990\nConfiguration saved in finetune-newwiki-summarization-ver2/checkpoint-990/config.json\nModel weights saved in finetune-newwiki-summarization-ver2/checkpoint-990/pytorch_model.bin\ntokenizer config file saved in finetune-newwiki-summarization-ver2/checkpoint-990/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/checkpoint-990/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/checkpoint-990/spiece.model\ntokenizer config file saved in finetune-newwiki-summarization-ver2/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/spiece.model\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 1980\n  Batch size = 8\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\nSaving model checkpoint to finetune-newwiki-summarization-ver2/checkpoint-1980\nConfiguration saved in finetune-newwiki-summarization-ver2/checkpoint-1980/config.json\nModel weights saved in finetune-newwiki-summarization-ver2/checkpoint-1980/pytorch_model.bin\ntokenizer config file saved in finetune-newwiki-summarization-ver2/checkpoint-1980/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/checkpoint-1980/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/checkpoint-1980/spiece.model\ntokenizer config file saved in finetune-newwiki-summarization-ver2/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/spiece.model\nDeleting older checkpoint [finetune-newwiki-summarization-ver2/checkpoint-990] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 1980\n  Batch size = 8\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\nSaving model checkpoint to finetune-newwiki-summarization-ver2/checkpoint-2970\nConfiguration saved in finetune-newwiki-summarization-ver2/checkpoint-2970/config.json\nModel weights saved in finetune-newwiki-summarization-ver2/checkpoint-2970/pytorch_model.bin\ntokenizer config file saved in finetune-newwiki-summarization-ver2/checkpoint-2970/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/checkpoint-2970/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/checkpoint-2970/spiece.model\ntokenizer config file saved in finetune-newwiki-summarization-ver2/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/spiece.model\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 1980\n  Batch size = 8\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\nSaving model checkpoint to finetune-newwiki-summarization-ver2/checkpoint-3960\nConfiguration saved in finetune-newwiki-summarization-ver2/checkpoint-3960/config.json\nModel weights saved in finetune-newwiki-summarization-ver2/checkpoint-3960/pytorch_model.bin\ntokenizer config file saved in finetune-newwiki-summarization-ver2/checkpoint-3960/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/checkpoint-3960/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/checkpoint-3960/spiece.model\ntokenizer config file saved in finetune-newwiki-summarization-ver2/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/spiece.model\nDeleting older checkpoint [finetune-newwiki-summarization-ver2/checkpoint-2970] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 1980\n  Batch size = 8\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\nSaving model checkpoint to finetune-newwiki-summarization-ver2/checkpoint-4950\nConfiguration saved in finetune-newwiki-summarization-ver2/checkpoint-4950/config.json\nModel weights saved in finetune-newwiki-summarization-ver2/checkpoint-4950/pytorch_model.bin\ntokenizer config file saved in finetune-newwiki-summarization-ver2/checkpoint-4950/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/checkpoint-4950/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/checkpoint-4950/spiece.model\ntokenizer config file saved in finetune-newwiki-summarization-ver2/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/spiece.model\nDeleting older checkpoint [finetune-newwiki-summarization-ver2/checkpoint-3960] due to args.save_total_limit\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from finetune-newwiki-summarization-ver2/checkpoint-1980 (score: 0.4693571627140045).\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4950, training_loss=0.47480650314176925, metrics={'train_runtime': 7487.117, 'train_samples_per_second': 7.403, 'train_steps_per_second': 0.926, 'total_flos': 4.82172857745408e+16, 'train_loss': 0.47480650314176925, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Push model to huggingface hub","metadata":{}},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:48:17.312114Z","iopub.execute_input":"2024-05-13T12:48:17.312486Z","iopub.status.idle":"2024-05-13T12:49:06.612963Z","shell.execute_reply.started":"2024-05-13T12:48:17.312451Z","shell.execute_reply":"2024-05-13T12:49:06.612027Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Saving model checkpoint to finetune-newwiki-summarization-ver2\nConfiguration saved in finetune-newwiki-summarization-ver2/config.json\nModel weights saved in finetune-newwiki-summarization-ver2/pytorch_model.bin\ntokenizer config file saved in finetune-newwiki-summarization-ver2/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/spiece.model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Upload file runs/May13_10-43-13_a81d583e2710/events.out.tfevents.1715597010.a81d583e2710.34.0:   0%|          …","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5042aab422a042f691714a0c58e4796a"}},"metadata":{}},{"name":"stderr","text":"To https://huggingface.co/minnehwg/finetune-newwiki-summarization-ver2\n   3ae6881..52e2b4b  main -> main\n\nDropping the following result as it does not have all the necessary fields:\n{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}, 'metrics': [{'name': 'Rouge1', 'type': 'rouge', 'value': 48.16587011744156}]}\nTo https://huggingface.co/minnehwg/finetune-newwiki-summarization-ver2\n   52e2b4b..de72c49  main -> main\n\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/minnehwg/finetune-newwiki-summarization-ver2/commit/52e2b4b56893e446500d8927a7d3012a1f2d25a6'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}