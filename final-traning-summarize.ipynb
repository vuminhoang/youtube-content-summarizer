{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7978482,"sourceType":"datasetVersion","datasetId":4695577},{"sourceId":8394271,"sourceType":"datasetVersion","datasetId":4993669}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-14T16:11:56.484700Z","iopub.execute_input":"2024-05-14T16:11:56.484961Z","iopub.status.idle":"2024-05-14T16:11:56.765168Z","shell.execute_reply.started":"2024-05-14T16:11:56.484938Z","shell.execute_reply":"2024-05-14T16:11:56.764193Z"},"trusted":true},"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4e9bace67104ea0a107cdf9f72c4c43"}},"metadata":{}}]},{"cell_type":"code","source":"%%capture\n!pip install datasets\n!pip install transformers==4.17 sentencepiece\n!pip install rouge_score\n!pip install transformers[torch]\n!pip install accelerate -U\n!pip install evaluate\n!pip install wandb","metadata":{"execution":{"iopub.status.busy":"2024-05-14T16:12:26.032649Z","iopub.execute_input":"2024-05-14T16:12:26.033342Z","iopub.status.idle":"2024-05-14T16:14:05.769581Z","shell.execute_reply.started":"2024-05-14T16:12:26.033309Z","shell.execute_reply":"2024-05-14T16:14:05.768243Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2024-05-14T16:14:05.771678Z","iopub.execute_input":"2024-05-14T16:14:05.772001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\nimport json\nimport os\nimport pandas as pd\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:39:30.189907Z","iopub.execute_input":"2024-05-13T10:39:30.190132Z","iopub.status.idle":"2024-05-13T10:39:31.297262Z","shell.execute_reply.started":"2024-05-13T10:39:30.190113Z","shell.execute_reply":"2024-05-13T10:39:31.296507Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, TrainingArguments\n\ntokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"minnehwg/finetune-newwiki-summarization-ver1\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:42:24.881171Z","iopub.execute_input":"2024-05-13T10:42:24.881558Z","iopub.status.idle":"2024-05-13T10:42:47.203256Z","shell.execute_reply.started":"2024-05-13T10:42:24.881528Z","shell.execute_reply":"2024-05-13T10:42:47.202427Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/741 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9826690ed15044489c3ef8d7d9902e11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/862M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e80ecec46c9e45a285bf54ae94575849"}},"metadata":{}}]},{"cell_type":"markdown","source":"### Read and pre-processing the data","metadata":{}},{"cell_type":"code","source":"file_path = '/kaggle/input/newwiki-pandas/data.pkl'\ndf = pd.read_pickle(file_path)\n\nfrom datasets import Dataset\ndataset = Dataset.from_pandas(df)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:42:47.205575Z","iopub.execute_input":"2024-05-13T10:42:47.206277Z","iopub.status.idle":"2024-05-13T10:42:48.048722Z","shell.execute_reply.started":"2024-05-13T10:42:47.206242Z","shell.execute_reply":"2024-05-13T10:42:48.047713Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dataset[2]","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:42:48.049905Z","iopub.execute_input":"2024-05-13T10:42:48.050166Z","iopub.status.idle":"2024-05-13T10:42:48.668981Z","shell.execute_reply.started":"2024-05-13T10:42:48.050144Z","shell.execute_reply":"2024-05-13T10:42:48.667718Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'inputs': 'Má»™t sá»‘ loáº¡i hÃ¬nh dÃ¡n cÃ³ keo dÃ­nh á»Ÿ Ä‘áº±ng sau, sá»‘ khÃ¡c chá»‰ cÃ³ má»™t miáº¿ng váº£i bÃªn dÆ°á»›i. Xem xÃ©t ká»¹ hÃ¬nh dÃ¡n vÃ  xÃ¡c Ä‘á»‹nh xem báº¡n cÃ³ cáº§n thÃªm váº­t liá»‡u gÃ¬ khÃ´ng. Nhá»¯ng hÃ¬nh dÃ¡n thÃªu trang trÃ­ thÆ°á»ng dÃ y, cá»©ng vÃ  cÃ³ má»™t lá»›p keo nhá»±a á»Ÿ máº·t dÆ°á»›i. Loáº¡i nÃ y cÃ³ thá»ƒ dÃ¹ng Ä‘á»ƒ che giáº¥u pháº§n váº£i bá»‹ rÃ¡ch hoáº·c máº¥t mÃ u. HÃ¬nh dÃ¡n truyá»n nhiá»‡t cÃ³ hÃ¬nh in trÃªn má»™t máº·t giáº¥y, vÃ  máº·t kia lÃ  loáº¡i giáº¥y khÃ´ng bÃ³ng. Loáº¡i nÃ y khÃ´ng thá»ƒ vÃ¡ Ä‘Æ°á»£c chá»— rÃ¡ch, vÃ  pháº§n váº£i bÃªn dÆ°á»›i thÆ°á»ng bá»‹ lá»™ rÃµ náº¿u khÃ´ng pháº£i lÃ  váº£i tráº¯ng. HÃ¬nh dÃ¡n cÃ³ máº·t sau chá»‰ lÃ  cháº¥t liá»‡u váº£i cÃ³ thá»ƒ gáº¯n báº±ng váº£i keo Ã©p. CÃ¡c hÃ¬nh dÃ¡n dÃ¹ng Ä‘á»ƒ vÃ¡ cÃ¡c lá»— thá»§ng hoáº·c váº¿t á»‘ báº©n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ hÃ²a láº«n vá»›i váº£i thÆ°á»ng cÃ³ má»™t lá»›p giáº¥y Ä‘áº±ng sau vÃ  cáº§n Ä‘Æ°á»£c gá»¡ ra trÆ°á»›c khi dÃ¡n. CÃ¢n nháº¯c tá»± thiáº¿t káº¿ hÃ¬nh dÃ¡n náº¿u báº¡n khÃ´ng tÃ¬m Ä‘Æ°á»£c máº«u yÃªu thÃ­ch. CÃ¡c cháº¥t liá»‡u nhÆ° denim vÃ  cotton thÆ°á»ng lÃ m ná»n ráº¥t tá»‘t cho cÃ¡c hÃ¬nh dÃ¡n báº±ng bÃ n lÃ . NguyÃªn táº¯c chung lÃ  cháº¥t liá»‡u váº£i Ã­t nháº¥t pháº£i dÃ y báº±ng hÃ¬nh dÃ¡n. Xem nhÃ£n hÆ°á»›ng dáº«n cÃ¡ch chÄƒm sÃ³c quáº§n Ã¡o Ä‘á»ƒ biáº¿t cháº¥t liá»‡u váº£i cÃ³ lÃ  Ä‘Æ°á»£c khÃ´ng náº¿u khÃ´ng Ä‘Æ°á»£c lÃ , báº¡n sáº½ tháº¥y hÃ¬nh chiáº¿c bÃ n lÃ  bá»‹ gáº¡ch chÃ©o . Náº¿u trÃªn quáº§n Ã¡o khÃ´ng cÃ³ nhÃ£n hÆ°á»›ng dáº«n, báº¡n hÃ£y cá»‘ Ä‘oÃ¡n thá»­ xem Ä‘Ã³ lÃ  cháº¥t liá»‡u gÃ¬. Tháº­t cáº©n tháº­n vá»›i loáº¡i váº£i polyester, vÃ¬ viá»‡c sá»­ dá»¥ng nhiá»‡t Ä‘á»™ cao khi lÃ  hÃ¬nh dÃ¡n cÃ³ thá»ƒ lÃ m chÃ¡y váº£i hoáº·c lÃ m máº¥t mÃ u váº£i. Lá»¥a vÃ  cÃ¡c cháº¥t liá»‡u má»ng manh khÃ¡c khÃ´ng pháº£i lÃ  Ä‘á»‘i tÆ°á»£ng thÃ­ch há»£p Ä‘á»ƒ dÃ¡n hÃ¬nh báº±ng bÃ n lÃ . TrÆ°á»›c khi lÃ m nÃ³ng bÃ n lÃ , báº¡n hÃ£y tráº£i Ã¡o, dáº£i bÄƒng Ä‘eo chÃ©o hoáº·c ba lÃ´ cá»§a báº¡n lÃªn bÃ n vÃ  xÃ¡c Ä‘á»‹nh chÃ­nh xÃ¡c vá»‹ trÃ­ muá»‘n Ä‘áº·t hÃ¬nh dÃ¡n. Náº¿u chá»‰ Ä‘á»‹nh dÃ¡n má»™t hÃ¬nh duy nháº¥t, báº¡n nÃªn Ä‘áº·t á»Ÿ vá»‹ trÃ­ Ä‘áº¹p vÃ  ná»•i báº­t sao cho hÃ¬nh dÃ¡n cÃ³ váº» nhÆ° Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ Ä‘áº·t á»Ÿ Ä‘Ã³. Náº¿u Ä‘á»‹nh dÃ¡n thÃªm nhiá»u hÃ¬nh dÃ¡n khÃ¡c, cháº³ng háº¡n nhÆ° muá»‘n trang trÃ­ dáº£i bÄƒng Ä‘eo chÃ©o cá»§a cÃ¡c cÃ´ gÃ¡i hoáº·c báº¥t ká»³ cÃ¡c mÃ³n Ä‘á»“ nÃ o khÃ¡c, báº¡n cáº§n tÃ­nh trÆ°á»›c Ä‘á»ƒ Ä‘áº£m báº£o cÃ³ Ä‘á»§ chá»— cho cÃ¡c hÃ¬nh dÃ¡n. Náº¿u sá»­ dá»¥ng hÃ¬nh dÃ¡n giáº¥y tá»± in, báº¡n pháº£i nhá»› lÃ  má»i hÃ¬nh khÃ´ng Ä‘á»‘i xá»©ng sáº½ Ä‘Æ°á»£c in ngÆ°á»£c.',\n 'labels': 'XÃ¡c Ä‘á»‹nh loáº¡i hÃ¬nh dÃ¡n trÆ°á»›c khi sá»­ dá»¥ng, bao gá»“m keo dÃ­nh, váº£i keo Ã©p hoáº·c giáº¥y. Loáº¡i váº£i vÃ  hÆ°á»›ng dáº«n giáº·t lÃ  cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n phÆ°Æ¡ng phÃ¡p gáº¯n hÃ¬nh dÃ¡n.'}"},"metadata":{}}]},{"cell_type":"code","source":"# import re\n\n# def clean_text(example):\n# #     example['inputs'] = re.sub(r'[^a-zA-Z0-9\\s.,!?;:]', ' ', example['inputs'])\n# #     example['labels'] = re.sub(r'[^a-zA-Z0-9\\s.,!?;:]', ' ', example['labels'])\n#     example['inputs'] = re.sub(r'\\s+', ' ', example['inputs']).strip()\n#     example['labels'] = re.sub(r'\\s+', ' ', example['labels']).strip()\n#     return example\n\nimport unicodedata\n\ndef clean_text(example):\n    # Loáº¡i bá» cÃ¡c kÃ½ tá»± khÃ´ng mong muá»‘n tá»« chuá»—i inputs vÃ  labels\n    example['inputs'] = remove_unwanted_chars(example['inputs'])\n    example['labels'] = remove_unwanted_chars(example['labels'])\n    \n    # XÃ³a khoáº£ng tráº¯ng dÆ° thá»«a trong inputs vÃ  labels, vÃ  loáº¡i bá» khoáº£ng tráº¯ng á»Ÿ Ä‘áº§u vÃ  cuá»‘i chuá»—i\n    example['inputs'] = ' '.join(example['inputs'].split())\n    example['labels'] = ' '.join(example['labels'].split())\n    \n    return example\n\ndef remove_unwanted_chars(text):\n    cleaned_text = []\n    for char in text:\n        # Kiá»ƒm tra xem kÃ½ tá»± cÃ³ pháº£i lÃ  kÃ½ tá»± chá»¯ cÃ¡i, chá»¯ sá»‘, hoáº·c dáº¥u cá»¥ nháº¥t Ä‘á»‹nh khÃ´ng\n        category = unicodedata.category(char)\n#         or category.startswith('P')\n        if char.isalnum() or char in [' ', '.','!', '?', ';', ':']:\n            cleaned_text.append(char)\n    return ''.join(cleaned_text)\n\n\ndef preprocess_function(examples):\n    model_inputs = tokenizer(\n        examples[\"inputs\"], max_length=1024, truncation=True, padding=True\n    )\n\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            examples[\"labels\"], max_length=256, truncation=True, padding=True\n        )\n    model_inputs['labels'] = labels['input_ids']\n    model_inputs['input_ids'] = model_inputs['input_ids']\n    return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:42:48.670099Z","iopub.execute_input":"2024-05-13T10:42:48.670379Z","iopub.status.idle":"2024-05-13T10:42:48.763390Z","shell.execute_reply.started":"2024-05-13T10:42:48.670356Z","shell.execute_reply":"2024-05-13T10:42:48.762328Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(clean_text)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:42:48.766938Z","iopub.execute_input":"2024-05-13T10:42:48.767579Z","iopub.status.idle":"2024-05-13T10:43:01.658322Z","shell.execute_reply.started":"2024-05-13T10:42:48.767549Z","shell.execute_reply":"2024-05-13T10:43:01.657396Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9898 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"511e46c2860a4212a30e5082edfe2dc8"}},"metadata":{}}]},{"cell_type":"code","source":"dataset[2]","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:01.659910Z","iopub.execute_input":"2024-05-13T10:43:01.660265Z","iopub.status.idle":"2024-05-13T10:43:01.666493Z","shell.execute_reply.started":"2024-05-13T10:43:01.660232Z","shell.execute_reply":"2024-05-13T10:43:01.665692Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'inputs': 'Má»™t sá»‘ loáº¡i hÃ¬nh dÃ¡n cÃ³ keo dÃ­nh á»Ÿ Ä‘áº±ng sau sá»‘ khÃ¡c chá»‰ cÃ³ má»™t miáº¿ng váº£i bÃªn dÆ°á»›i. Xem xÃ©t ká»¹ hÃ¬nh dÃ¡n vÃ  xÃ¡c Ä‘á»‹nh xem báº¡n cÃ³ cáº§n thÃªm váº­t liá»‡u gÃ¬ khÃ´ng. Nhá»¯ng hÃ¬nh dÃ¡n thÃªu trang trÃ­ thÆ°á»ng dÃ y cá»©ng vÃ  cÃ³ má»™t lá»›p keo nhá»±a á»Ÿ máº·t dÆ°á»›i. Loáº¡i nÃ y cÃ³ thá»ƒ dÃ¹ng Ä‘á»ƒ che giáº¥u pháº§n váº£i bá»‹ rÃ¡ch hoáº·c máº¥t mÃ u. HÃ¬nh dÃ¡n truyá»n nhiá»‡t cÃ³ hÃ¬nh in trÃªn má»™t máº·t giáº¥y vÃ  máº·t kia lÃ  loáº¡i giáº¥y khÃ´ng bÃ³ng. Loáº¡i nÃ y khÃ´ng thá»ƒ vÃ¡ Ä‘Æ°á»£c chá»— rÃ¡ch vÃ  pháº§n váº£i bÃªn dÆ°á»›i thÆ°á»ng bá»‹ lá»™ rÃµ náº¿u khÃ´ng pháº£i lÃ  váº£i tráº¯ng. HÃ¬nh dÃ¡n cÃ³ máº·t sau chá»‰ lÃ  cháº¥t liá»‡u váº£i cÃ³ thá»ƒ gáº¯n báº±ng váº£i keo Ã©p. CÃ¡c hÃ¬nh dÃ¡n dÃ¹ng Ä‘á»ƒ vÃ¡ cÃ¡c lá»— thá»§ng hoáº·c váº¿t á»‘ báº©n Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ hÃ²a láº«n vá»›i váº£i thÆ°á»ng cÃ³ má»™t lá»›p giáº¥y Ä‘áº±ng sau vÃ  cáº§n Ä‘Æ°á»£c gá»¡ ra trÆ°á»›c khi dÃ¡n. CÃ¢n nháº¯c tá»± thiáº¿t káº¿ hÃ¬nh dÃ¡n náº¿u báº¡n khÃ´ng tÃ¬m Ä‘Æ°á»£c máº«u yÃªu thÃ­ch. CÃ¡c cháº¥t liá»‡u nhÆ° denim vÃ  cotton thÆ°á»ng lÃ m ná»n ráº¥t tá»‘t cho cÃ¡c hÃ¬nh dÃ¡n báº±ng bÃ n lÃ . NguyÃªn táº¯c chung lÃ  cháº¥t liá»‡u váº£i Ã­t nháº¥t pháº£i dÃ y báº±ng hÃ¬nh dÃ¡n. Xem nhÃ£n hÆ°á»›ng dáº«n cÃ¡ch chÄƒm sÃ³c quáº§n Ã¡o Ä‘á»ƒ biáº¿t cháº¥t liá»‡u váº£i cÃ³ lÃ  Ä‘Æ°á»£c khÃ´ng náº¿u khÃ´ng Ä‘Æ°á»£c lÃ  báº¡n sáº½ tháº¥y hÃ¬nh chiáº¿c bÃ n lÃ  bá»‹ gáº¡ch chÃ©o . Náº¿u trÃªn quáº§n Ã¡o khÃ´ng cÃ³ nhÃ£n hÆ°á»›ng dáº«n báº¡n hÃ£y cá»‘ Ä‘oÃ¡n thá»­ xem Ä‘Ã³ lÃ  cháº¥t liá»‡u gÃ¬. Tháº­t cáº©n tháº­n vá»›i loáº¡i váº£i polyester vÃ¬ viá»‡c sá»­ dá»¥ng nhiá»‡t Ä‘á»™ cao khi lÃ  hÃ¬nh dÃ¡n cÃ³ thá»ƒ lÃ m chÃ¡y váº£i hoáº·c lÃ m máº¥t mÃ u váº£i. Lá»¥a vÃ  cÃ¡c cháº¥t liá»‡u má»ng manh khÃ¡c khÃ´ng pháº£i lÃ  Ä‘á»‘i tÆ°á»£ng thÃ­ch há»£p Ä‘á»ƒ dÃ¡n hÃ¬nh báº±ng bÃ n lÃ . TrÆ°á»›c khi lÃ m nÃ³ng bÃ n lÃ  báº¡n hÃ£y tráº£i Ã¡o dáº£i bÄƒng Ä‘eo chÃ©o hoáº·c ba lÃ´ cá»§a báº¡n lÃªn bÃ n vÃ  xÃ¡c Ä‘á»‹nh chÃ­nh xÃ¡c vá»‹ trÃ­ muá»‘n Ä‘áº·t hÃ¬nh dÃ¡n. Náº¿u chá»‰ Ä‘á»‹nh dÃ¡n má»™t hÃ¬nh duy nháº¥t báº¡n nÃªn Ä‘áº·t á»Ÿ vá»‹ trÃ­ Ä‘áº¹p vÃ  ná»•i báº­t sao cho hÃ¬nh dÃ¡n cÃ³ váº» nhÆ° Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ Ä‘áº·t á»Ÿ Ä‘Ã³. Náº¿u Ä‘á»‹nh dÃ¡n thÃªm nhiá»u hÃ¬nh dÃ¡n khÃ¡c cháº³ng háº¡n nhÆ° muá»‘n trang trÃ­ dáº£i bÄƒng Ä‘eo chÃ©o cá»§a cÃ¡c cÃ´ gÃ¡i hoáº·c báº¥t ká»³ cÃ¡c mÃ³n Ä‘á»“ nÃ o khÃ¡c báº¡n cáº§n tÃ­nh trÆ°á»›c Ä‘á»ƒ Ä‘áº£m báº£o cÃ³ Ä‘á»§ chá»— cho cÃ¡c hÃ¬nh dÃ¡n. Náº¿u sá»­ dá»¥ng hÃ¬nh dÃ¡n giáº¥y tá»± in báº¡n pháº£i nhá»› lÃ  má»i hÃ¬nh khÃ´ng Ä‘á»‘i xá»©ng sáº½ Ä‘Æ°á»£c in ngÆ°á»£c.',\n 'labels': 'XÃ¡c Ä‘á»‹nh loáº¡i hÃ¬nh dÃ¡n trÆ°á»›c khi sá»­ dá»¥ng bao gá»“m keo dÃ­nh váº£i keo Ã©p hoáº·c giáº¥y. Loáº¡i váº£i vÃ  hÆ°á»›ng dáº«n giáº·t lÃ  cÃ³ thá»ƒ áº£nh hÆ°á»Ÿng Ä‘áº¿n phÆ°Æ¡ng phÃ¡p gáº¯n hÃ¬nh dÃ¡n.'}"},"metadata":{}}]},{"cell_type":"code","source":"\ntokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=8)","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:01.667679Z","iopub.execute_input":"2024-05-13T10:43:01.668011Z","iopub.status.idle":"2024-05-13T10:43:10.547321Z","shell.execute_reply.started":"2024-05-13T10:43:01.667986Z","shell.execute_reply":"2024-05-13T10:43:10.546360Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=8):   0%|          | 0/9898 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67d24695428540ee83ccc563998a7134"}},"metadata":{}}]},{"cell_type":"code","source":"train_size = int(len(tokenized_dataset) * 0.8)\ntrain_dataset = tokenized_dataset.select(range(train_size))\nval_dataset = tokenized_dataset.select(range(train_size, len(dataset)))","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:10.548826Z","iopub.execute_input":"2024-05-13T10:43:10.549114Z","iopub.status.idle":"2024-05-13T10:43:10.558891Z","shell.execute_reply.started":"2024-05-13T10:43:10.549087Z","shell.execute_reply":"2024-05-13T10:43:10.558156Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"dataset[1]","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:10.559954Z","iopub.execute_input":"2024-05-13T10:43:10.560209Z","iopub.status.idle":"2024-05-13T10:43:10.575367Z","shell.execute_reply.started":"2024-05-13T10:43:10.560187Z","shell.execute_reply":"2024-05-13T10:43:10.574607Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"{'inputs': 'Hydroquinone lÃ  loáº¡i kem táº©y tráº¯ng hiá»‡u quáº£ cÃ³ thá»ƒ giÃºp giáº£m Ä‘Ã¡ng ká»ƒ sá»± xuáº¥t hiá»‡n cá»§a Ä‘á»“i má»“i. Hydroquinone cÃ³ bÃ¡n á»Ÿ ná»“ng Ä‘á»™ lÃªn Ä‘áº¿n 2 á»Ÿ dáº¡ng khÃ´ng kÃª Ä‘Æ¡n cÃ²n ná»“ng Ä‘á»™ cao hÆ¡n cáº§n cÃ³ Ä‘Æ¡n thuá»‘c cá»§a bÃ¡c sÄ©. Cáº§n biáº¿t ráº±ng hydroquinone bá»‹ cáº¥m á»Ÿ nhiá»u quá»‘c gia chÃ¢u Ã‚u vÃ  chÃ¢u Ã do Ä‘áº·c tÃ­nh gÃ¢y ung thÆ° tiá»m áº©n. Tuy nhiÃªn á»Ÿ má»™t sá»‘ quá»‘c gia nhÆ° Má»¹ hydroquinone váº«n Ä‘Æ°á»£c bÃ¡n rá»™ng rÃ£i. RetinA lÃ  sáº£n pháº©m chÄƒm sÃ³c da chá»‘ng lÃ£o hÃ³a tuyá»‡t vá»i Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ chá»‘ng láº¡i náº¿p nhÄƒn cáº£i thiá»‡n Ä‘á»™ trÆ¡n lÃ¡ng cá»§a da lÃ m má» vÃ¹ng da khÃ´ng Ä‘á»u mÃ u vÃ  tá»•n thÆ°Æ¡ng do Ã¡nh náº¯ng bao gá»“m Ä‘á»‘m Ä‘á»“i má»“i. RetinA lÃ  dáº«n xuáº¥t cá»§a vitamin A cÃ³ sáºµn á»Ÿ dáº¡ng gel hoáº·c kem vá»›i nhiá»u ná»“ng Ä‘á»™ khÃ¡c nhau. RetinA chá»‰ cÃ³ sáºµn á»Ÿ dáº¡ng kÃª Ä‘Æ¡n nÃªn báº¡n cáº§n Ä‘i bÃ¡c sÄ© khÃ¡m trÆ°á»›c khi báº¯t Ä‘áº§u sá»­ dá»¥ng. RetinA giÃºp loáº¡i bá» Ä‘á»‘m Ä‘á»“i má»“i báº±ng cÃ¡ch táº©y da cháº¿t loáº¡i bá» lá»›p da tÄƒng sáº¯c tá»‘ bÃªn ngoÃ i vÃ  Ä‘á»ƒ lá»™ lá»›p da má»›i tinh khÃ´i bÃªn dÆ°á»›i. Sá»± káº¿t há»£p cá»§a hai thÃ nh pháº§n nÃ y Ä‘Ã£ Ä‘Æ°á»£c chá»©ng minh lÃ  sáº½ giÃºp lÃ m sÃ¡ng mÃ u cÃ¡c váº¿t Ä‘á»“i má»“i. HÃ£y trao Ä‘á»•i vá»›i bÃ¡c sÄ© da liá»…u Ä‘á»ƒ Ä‘Æ°á»£c tÆ° váº¥n hoáº·c kiá»ƒm tra nhÃ£n sáº£n pháº©m Ä‘á»ƒ tÃ¬m loáº¡i cÃ³ chá»©a cáº£ hai thÃ nh pháº§n nÃ y. Báº¡n cÃ³ thá»ƒ tÃ¬m tháº¥y kem hoáº·c sá»¯a dÆ°á»¡ng da cÃ³ chá»©a cáº£ hai thÃ nh pháº§n nÃ y. Kem chá»‘ng náº¯ng khÃ´ng thá»±c sá»± giÃºp giáº£m sá»± xuáº¥t hiá»‡n cá»§a Ä‘á»‘m Ä‘á»“i má»“i cÅ© nhÆ°ng sáº½ ngÄƒn Ä‘á»‘m má»›i hÃ¬nh thÃ nh vÃ¬ Ä‘á»“i má»“i chá»§ yáº¿u lÃ  do tá»•n thÆ°Æ¡ng bá»Ÿi Ã¡nh náº¯ng . BÃªn cáº¡nh Ä‘Ã³ kem chá»‘ng náº¯ng sáº½ ngÄƒn Ä‘á»‘m Ä‘á»“i má»“i cÅ© trá»Ÿ nÃªn Ä‘áº­m mÃ u hÆ¡n hay dá»… gÃ¢y chÃº Ã½ hÆ¡n. NÃªn thoa kem chá»‘ng náº¯ng chá»©a káº½m oxit vÃ  cÃ³ chá»‰ sá»‘ SPF Ã­t nháº¥t 15 hÃ ng ngÃ y ngay cáº£ khi trá»i khÃ´ng náº¯ng nÃ³ng.',\n 'labels': 'Hydroquinone vÃ  RetinA hiá»‡u quáº£ trong viá»‡c giáº£m Ä‘á»‘m Ä‘á»“i má»“i káº¿t há»£p 2 thÃ nh pháº§n nÃ y cho káº¿t quáº£ tá»‘i Æ°u. Sá»­ dá»¥ng kem chá»‘ng náº¯ng háº±ng ngÃ y Ä‘á»ƒ ngÄƒn ngá»«a Ä‘á»‘m Ä‘á»“i má»“i má»›i vÃ  lÃ m má» Ä‘á»‘m cÅ©.'}"},"metadata":{}}]},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:10.576701Z","iopub.execute_input":"2024-05-13T10:43:10.577030Z","iopub.status.idle":"2024-05-13T10:43:10.583035Z","shell.execute_reply.started":"2024-05-13T10:43:10.576992Z","shell.execute_reply":"2024-05-13T10:43:10.582268Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"del tokenized_dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:10.583973Z","iopub.execute_input":"2024-05-13T10:43:10.584290Z","iopub.status.idle":"2024-05-13T10:43:10.593083Z","shell.execute_reply.started":"2024-05-13T10:43:10.584261Z","shell.execute_reply":"2024-05-13T10:43:10.592327Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:10.594100Z","iopub.execute_input":"2024-05-13T10:43:10.594353Z","iopub.status.idle":"2024-05-13T10:43:10.605066Z","shell.execute_reply.started":"2024-05-13T10:43:10.594332Z","shell.execute_reply":"2024-05-13T10:43:10.604200Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['labels', 'input_ids', 'attention_mask'],\n    num_rows: 7918\n})"},"metadata":{}}]},{"cell_type":"code","source":"val_dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:10.606125Z","iopub.execute_input":"2024-05-13T10:43:10.606443Z","iopub.status.idle":"2024-05-13T10:43:10.615204Z","shell.execute_reply.started":"2024-05-13T10:43:10.606412Z","shell.execute_reply":"2024-05-13T10:43:10.614421Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['labels', 'input_ids', 'attention_mask'],\n    num_rows: 1980\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"## import metric","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport nltk\nnltk.download(\"punkt\")\nfrom nltk.tokenize import sent_tokenize\nimport evaluate\nrouge_score = evaluate.load(\"rouge\")\nfrom datasets import load_metric\n\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n    rouge_metric = load_metric('rouge')\n\n    rouge_metric.add_batch(predictions=decoded_preds, references=decoded_labels)\n    rouge_scores = rouge_metric.compute()\n\n    return {k: v.mid.fmeasure * 100 for k, v in rouge_scores.items()}","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:10.618234Z","iopub.execute_input":"2024-05-13T10:43:10.618511Z","iopub.status.idle":"2024-05-13T10:43:13.383282Z","shell.execute_reply.started":"2024-05-13T10:43:10.618490Z","shell.execute_reply":"2024-05-13T10:43:13.382334Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96662062594d41fdaaa96f38fbe3dcfe"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Define traing args ","metadata":{}},{"cell_type":"code","source":"from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\nfrom transformers import EarlyStoppingCallback\n\n        \ntraining_args = Seq2SeqTrainingArguments(\"finetune-newwiki-summarization-ver2\",\n                                      num_train_epochs=7,\n                                      learning_rate=1e-6,\n                                      warmup_ratio=0.1,\n                                      weight_decay=0.01,\n                                      per_device_train_batch_size=4,\n                                      per_device_eval_batch_size=4,\n                                      group_by_length=True,\n                                      save_strategy=\"epoch\",\n                                      evaluation_strategy=\"epoch\",\n                                      save_total_limit=1,\n                                      fp16=True, # if GPU\n                                      predict_with_generate=True,\n#                                       logging_steps=200,\n                                      push_to_hub=True,\n                                         load_best_model_at_end=True\n                                      )","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:13.384285Z","iopub.execute_input":"2024-05-13T10:43:13.384554Z","iopub.status.idle":"2024-05-13T10:43:13.474715Z","shell.execute_reply.started":"2024-05-13T10:43:13.384531Z","shell.execute_reply":"2024-05-13T10:43:13.473684Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Traning loop","metadata":{}},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    tokenizer = tokenizer,\n    compute_metrics=compute_metrics,\n    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T10:43:13.475908Z","iopub.execute_input":"2024-05-13T10:43:13.476199Z","iopub.status.idle":"2024-05-13T12:48:17.310319Z","shell.execute_reply.started":"2024-05-13T10:43:13.476173Z","shell.execute_reply":"2024-05-13T12:48:17.309299Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\nFor more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n  warnings.warn(warning_message, FutureWarning)\nCloning https://huggingface.co/minnehwg/finetune-newwiki-summarization-ver2 into local empty directory.\nUsing amp half precision backend\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n***** Running training *****\n  Num examples = 7918\n  Num Epochs = 7\n  Instantaneous batch size per device = 4\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 6930\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4950' max='6930' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4950/6930 2:04:42 < 49:54, 0.66 it/s, Epoch 5/7]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.491200</td>\n      <td>0.470079</td>\n      <td>48.175356</td>\n      <td>25.022139</td>\n      <td>34.761329</td>\n      <td>37.073443</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.474800</td>\n      <td>0.469357</td>\n      <td>48.362864</td>\n      <td>25.364867</td>\n      <td>35.023890</td>\n      <td>37.308376</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.475500</td>\n      <td>0.469549</td>\n      <td>48.276979</td>\n      <td>25.190664</td>\n      <td>34.845579</td>\n      <td>37.193011</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.470300</td>\n      <td>0.469566</td>\n      <td>48.180064</td>\n      <td>25.176948</td>\n      <td>34.800357</td>\n      <td>37.081658</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.468000</td>\n      <td>0.469694</td>\n      <td>48.165870</td>\n      <td>25.149090</td>\n      <td>34.779352</td>\n      <td>37.089311</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 1980\n  Batch size = 8\n/tmp/ipykernel_34/806200219.py:17: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n  rouge_metric = load_metric('rouge')\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"767746d78a1841ae8131aff44f0a625b"}},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to finetune-newwiki-summarization-ver2/checkpoint-990\nConfiguration saved in finetune-newwiki-summarization-ver2/checkpoint-990/config.json\nModel weights saved in finetune-newwiki-summarization-ver2/checkpoint-990/pytorch_model.bin\ntokenizer config file saved in finetune-newwiki-summarization-ver2/checkpoint-990/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/checkpoint-990/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/checkpoint-990/spiece.model\ntokenizer config file saved in finetune-newwiki-summarization-ver2/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/spiece.model\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 1980\n  Batch size = 8\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\nSaving model checkpoint to finetune-newwiki-summarization-ver2/checkpoint-1980\nConfiguration saved in finetune-newwiki-summarization-ver2/checkpoint-1980/config.json\nModel weights saved in finetune-newwiki-summarization-ver2/checkpoint-1980/pytorch_model.bin\ntokenizer config file saved in finetune-newwiki-summarization-ver2/checkpoint-1980/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/checkpoint-1980/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/checkpoint-1980/spiece.model\ntokenizer config file saved in finetune-newwiki-summarization-ver2/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/spiece.model\nDeleting older checkpoint [finetune-newwiki-summarization-ver2/checkpoint-990] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 1980\n  Batch size = 8\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\nSaving model checkpoint to finetune-newwiki-summarization-ver2/checkpoint-2970\nConfiguration saved in finetune-newwiki-summarization-ver2/checkpoint-2970/config.json\nModel weights saved in finetune-newwiki-summarization-ver2/checkpoint-2970/pytorch_model.bin\ntokenizer config file saved in finetune-newwiki-summarization-ver2/checkpoint-2970/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/checkpoint-2970/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/checkpoint-2970/spiece.model\ntokenizer config file saved in finetune-newwiki-summarization-ver2/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/spiece.model\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 1980\n  Batch size = 8\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\nSaving model checkpoint to finetune-newwiki-summarization-ver2/checkpoint-3960\nConfiguration saved in finetune-newwiki-summarization-ver2/checkpoint-3960/config.json\nModel weights saved in finetune-newwiki-summarization-ver2/checkpoint-3960/pytorch_model.bin\ntokenizer config file saved in finetune-newwiki-summarization-ver2/checkpoint-3960/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/checkpoint-3960/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/checkpoint-3960/spiece.model\ntokenizer config file saved in finetune-newwiki-summarization-ver2/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/spiece.model\nDeleting older checkpoint [finetune-newwiki-summarization-ver2/checkpoint-2970] due to args.save_total_limit\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n***** Running Evaluation *****\n  Num examples = 1980\n  Batch size = 8\n/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n  warnings.warn(\nSaving model checkpoint to finetune-newwiki-summarization-ver2/checkpoint-4950\nConfiguration saved in finetune-newwiki-summarization-ver2/checkpoint-4950/config.json\nModel weights saved in finetune-newwiki-summarization-ver2/checkpoint-4950/pytorch_model.bin\ntokenizer config file saved in finetune-newwiki-summarization-ver2/checkpoint-4950/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/checkpoint-4950/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/checkpoint-4950/spiece.model\ntokenizer config file saved in finetune-newwiki-summarization-ver2/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/spiece.model\nDeleting older checkpoint [finetune-newwiki-summarization-ver2/checkpoint-3960] due to args.save_total_limit\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\nLoading best model from finetune-newwiki-summarization-ver2/checkpoint-1980 (score: 0.4693571627140045).\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4950, training_loss=0.47480650314176925, metrics={'train_runtime': 7487.117, 'train_samples_per_second': 7.403, 'train_steps_per_second': 0.926, 'total_flos': 4.82172857745408e+16, 'train_loss': 0.47480650314176925, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"## Push model to huggingface hub","metadata":{}},{"cell_type":"code","source":"trainer.push_to_hub()","metadata":{"execution":{"iopub.status.busy":"2024-05-13T12:48:17.312114Z","iopub.execute_input":"2024-05-13T12:48:17.312486Z","iopub.status.idle":"2024-05-13T12:49:06.612963Z","shell.execute_reply.started":"2024-05-13T12:48:17.312451Z","shell.execute_reply":"2024-05-13T12:49:06.612027Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"Saving model checkpoint to finetune-newwiki-summarization-ver2\nConfiguration saved in finetune-newwiki-summarization-ver2/config.json\nModel weights saved in finetune-newwiki-summarization-ver2/pytorch_model.bin\ntokenizer config file saved in finetune-newwiki-summarization-ver2/tokenizer_config.json\nSpecial tokens file saved in finetune-newwiki-summarization-ver2/special_tokens_map.json\nCopy vocab file to finetune-newwiki-summarization-ver2/spiece.model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Upload file runs/May13_10-43-13_a81d583e2710/events.out.tfevents.1715597010.a81d583e2710.34.0:   0%|          â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5042aab422a042f691714a0c58e4796a"}},"metadata":{}},{"name":"stderr","text":"To https://huggingface.co/minnehwg/finetune-newwiki-summarization-ver2\n   3ae6881..52e2b4b  main -> main\n\nDropping the following result as it does not have all the necessary fields:\n{'task': {'name': 'Sequence-to-sequence Language Modeling', 'type': 'text2text-generation'}, 'metrics': [{'name': 'Rouge1', 'type': 'rouge', 'value': 48.16587011744156}]}\nTo https://huggingface.co/minnehwg/finetune-newwiki-summarization-ver2\n   52e2b4b..de72c49  main -> main\n\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/minnehwg/finetune-newwiki-summarization-ver2/commit/52e2b4b56893e446500d8927a7d3012a1f2d25a6'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}