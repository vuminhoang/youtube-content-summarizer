{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install datasets\n!pip install transformers==4.17 \n!pip install youtube-transcript-api\n!pip install googletrans==4.0.0-rc1\n!pip install deepmultilingualpunctuation\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-03T02:01:13.733111Z","iopub.execute_input":"2024-06-03T02:01:13.733658Z","iopub.status.idle":"2024-06-03T02:02:15.392033Z","shell.execute_reply.started":"2024-06-03T02:01:13.733622Z","shell.execute_reply":"2024-06-03T02:02:15.390362Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!pip install deepmultilingualpunctuation","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:15.394786Z","iopub.execute_input":"2024-06-03T02:02:15.395199Z","iopub.status.idle":"2024-06-03T02:02:27.685547Z","shell.execute_reply.started":"2024-06-03T02:02:15.395163Z","shell.execute_reply":"2024-06-03T02:02:27.683968Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"import httpx\nimport googletrans\n\nprint(httpx.__version__)\nprint(googletrans.__version__)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:27.687662Z","iopub.execute_input":"2024-06-03T02:02:27.688091Z","iopub.status.idle":"2024-06-03T02:02:27.695458Z","shell.execute_reply.started":"2024-06-03T02:02:27.688050Z","shell.execute_reply":"2024-06-03T02:02:27.694198Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"0.13.3\n4.0.0-rc.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Mô hình tóm tắt trừu tượng","metadata":{}},{"cell_type":"code","source":"cp_aug = 'minnehwg/finetune-newwiki-summarization-ver-augmented'\ncp_org = 'minnehwg/finetune-newwiki-summarization-ver2'","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:27.699051Z","iopub.execute_input":"2024-06-03T02:02:27.699625Z","iopub.status.idle":"2024-06-03T02:02:27.708547Z","shell.execute_reply.started":"2024-06-03T02:02:27.699581Z","shell.execute_reply":"2024-06-03T02:02:27.707194Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, TrainingArguments\n\ntokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")\nmodel_aug  = AutoModelForSeq2SeqLM.from_pretrained(cp_aug)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:27.710175Z","iopub.execute_input":"2024-06-03T02:02:27.710664Z","iopub.status.idle":"2024-06-03T02:02:51.253368Z","shell.execute_reply.started":"2024-06-03T02:02:27.710620Z","shell.execute_reply":"2024-06-03T02:02:51.251782Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/741 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d36933e3d85c43ddb144258069a0f9d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/862M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95f388bfbc7a4bfaa87f60e3ec3a99c9"}},"metadata":{}}]},{"cell_type":"code","source":"model_aug","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Predict function","metadata":{}},{"cell_type":"code","source":"import torch\n\ndef summarize(text, model, tokenizer, num_beams=4, device='cpu'):\n    model.to(device)\n    inputs = tokenizer.encode(text, return_tensors=\"pt\", max_length=1024, truncation=True, padding = True).to(device)\n    \n    with torch.no_grad():\n        summary_ids = model.generate(inputs, max_length=256, num_beams=num_beams)\n    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n    \n    return summary\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.255102Z","iopub.execute_input":"2024-06-03T02:02:51.255484Z","iopub.status.idle":"2024-06-03T02:02:51.263411Z","shell.execute_reply.started":"2024-06-03T02:02:51.255444Z","shell.execute_reply":"2024-06-03T02:02:51.261924Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"# def summarize_text(result, model, tokenizer, chunk_size=1000, overlap=2, device='cpu'):\n#     sentences = result.split('. ')  \n#     chunk_sentences = [sentences[i:i + chunk_size] for i in range(0, len(sentences), chunk_size - overlap)]  # Tách thành các chunk với overlap\n    \n#     summarized_text = []\n#     for chunk in chunk_sentences:\n#         input_text = '. '.join(chunk)\n#         output = summarize(input_text, model, tokenizer, device=device)\n#         summarized_text.append(output)\n    \n#     return '. \\n'.join(summarized_text)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.265151Z","iopub.execute_input":"2024-06-03T02:02:51.265632Z","iopub.status.idle":"2024-06-03T02:02:51.283256Z","shell.execute_reply.started":"2024-06-03T02:02:51.265601Z","shell.execute_reply":"2024-06-03T02:02:51.281988Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"def processed(text):\n    processed_text = text.replace('\\n', ' ')\n    processed_text = processed_text.lower()\n    return processed_text\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.284702Z","iopub.execute_input":"2024-06-03T02:02:51.285046Z","iopub.status.idle":"2024-06-03T02:02:51.296276Z","shell.execute_reply.started":"2024-06-03T02:02:51.285019Z","shell.execute_reply":"2024-06-03T02:02:51.295158Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"# summarize_text(text, model_aug, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.297696Z","iopub.execute_input":"2024-06-03T02:02:51.298036Z","iopub.status.idle":"2024-06-03T02:02:51.309812Z","shell.execute_reply.started":"2024-06-03T02:02:51.298009Z","shell.execute_reply":"2024-06-03T02:02:51.308648Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"markdown","source":"### Lấy script ytb","metadata":{}},{"cell_type":"code","source":"from youtube_transcript_api import YouTubeTranscriptApi\n\ndef get_subtitles(video_url):\n    try:\n        video_id = video_url.split(\"v=\")[1]\n        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['en'])\n        subs = \" \".join(entry['text'] for entry in transcript)\n\n        return transcript, subs\n\n    except Exception as e:\n        return [], f\"An error occurred: {e}\"","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.313656Z","iopub.execute_input":"2024-06-03T02:02:51.314070Z","iopub.status.idle":"2024-06-03T02:02:51.323046Z","shell.execute_reply.started":"2024-06-03T02:02:51.314037Z","shell.execute_reply":"2024-06-03T02:02:51.321836Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"### Khôi phục dấu từ script tiếng anh","metadata":{}},{"cell_type":"code","source":"from deepmultilingualpunctuation import PunctuationModel\n\ndef restore_punctuation(text):\n    model = PunctuationModel()\n    result = model.restore_punctuation(text)\n    return result","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.324536Z","iopub.execute_input":"2024-06-03T02:02:51.325053Z","iopub.status.idle":"2024-06-03T02:02:51.334894Z","shell.execute_reply.started":"2024-06-03T02:02:51.325021Z","shell.execute_reply":"2024-06-03T02:02:51.333764Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"markdown","source":"### Dịch văn bản dài","metadata":{}},{"cell_type":"code","source":"from googletrans import Translator\nimport re\nimport time\n\ndef translate_long(text, language='vi'):\n    translator = Translator()\n    limit = 4700\n    chunks = []\n    current_chunk = ''\n\n    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n\n    for sentence in sentences:\n        if len(current_chunk) + len(sentence) <= limit:\n            current_chunk += sentence.strip() + ' '\n        else:\n            chunks.append(current_chunk.strip())\n            current_chunk = sentence.strip() + ' '\n\n    if current_chunk:\n        chunks.append(current_chunk.strip())\n\n    translated_text = ''\n\n    for chunk in chunks:\n        try:\n            time.sleep(1)\n            translation = translator.translate(chunk, dest=language)\n            translated_text += translation.text + ' '\n        except Exception as e:\n            translated_text += chunk + ' '\n\n    return translated_text.strip()","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.336356Z","iopub.execute_input":"2024-06-03T02:02:51.336718Z","iopub.status.idle":"2024-06-03T02:02:51.349202Z","shell.execute_reply.started":"2024-06-03T02:02:51.336665Z","shell.execute_reply":"2024-06-03T02:02:51.348062Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"text = \"\"\"\nTrong một ngôi làng nhỏ, yên tĩnh nằm giữa những ngọn đồi uốn lượn và những khu rừng rậm rạp, cuộc sống mang một nhịp điệu bình yên nhưng sôi động đã tồn tại qua nhiều thế hệ. Làng Willowbrook là nơi thời gian dường như chậm lại và sự đơn giản của cuộc sống hàng ngày được cư dân của nó trân trọng. Những con đường lát đá cuội được xếp hàng bởi những ngôi nhà nhỏ xinh đẹp, mỗi căn đều mang một vẻ độc đáo riêng, được trang trí với những bông hoa nở rộ và dây thường xuân leo lên tường.\n\nTrái tim của Willowbrook là quảng trường làng, một trung tâm sôi động nơi dân làng tụ tập để trao đổi tin tức, mua bán hàng hóa và tham gia vào tinh thần cộng đồng định hình cuộc sống của họ. Quảng trường là nơi có nhiều cửa hàng và quầy hàng khác nhau, mỗi nơi mang đến một cái nhìn thoáng qua về bức tranh văn hóa phong phú của làng. Từ tiệm bánh, nơi hương thơm của bánh mì mới nướng lan tỏa trong không khí, đến lò rèn, nơi tiếng búa đập vào đe vang lên đều đặn, quảng trường là một bản giao hưởng của những hình ảnh, âm thanh và mùi hương.\n\nTrong số nhiều cư dân của Willowbrook, có một nhân vật đặc biệt nổi bật—ông Harlan già. Harlan là một người có tuổi tác không xác định, khuôn mặt ông hằn sâu những nếp nhăn của vô số câu chuyện và trải nghiệm. Ông đã sống ở làng từ khi mọi người còn nhớ, và sự hiện diện của ông là một phần không thể thiếu của Willowbrook, giống như cây sồi cổ thụ đứng giữa quảng trường. Ngôi nhà nhỏ của Harlan, một nơi khiêm tốn nhưng ấm cúng, là kho tàng lịch sử của làng. Những kệ sách đầy ắp sách vở, đồ trang trí và hiện vật kể lại những câu chuyện của thời kỳ đã qua, và khách ghé thăm thường bị cuốn hút bởi những câu chuyện của ông.\n\nMột buổi sáng mùa thu trong lành, khi những chiếc lá bắt đầu chuyển sang màu đỏ và vàng rực rỡ, Harlan ngồi trên hiên nhà, cầm một tách trà nóng. Đôi mắt ông, dù mờ đi vì tuổi tác, vẫn sáng lên với sự tò mò trẻ trung khi ông nhìn ngắm dân làng đi lại trong ngày. Những đứa trẻ chơi trò đuổi bắt và trốn tìm, tiếng cười của chúng vang vọng trong không khí, trong khi những người nông dân mang về vụ thu hoạch cuối cùng, những chiếc xe chở đầy bí ngô, táo và bí đỏ.\n\nVào buổi sáng đặc biệt này, một người mới đến Willowbrook. Một cô gái trẻ tên Elara, với đôi mắt sáng và sự quyết tâm yên lặng, bước vào quảng trường làng. Elara đã đi từ một thành phố xa xôi, tìm kiếm sự bình yên và một khởi đầu mới sau một loạt các sự kiện không may đã làm đảo lộn cuộc sống của cô. Dân làng, luôn chào đón, đã đón tiếp cô bằng những nụ cười ấm áp và trái tim rộng mở, và chẳng mấy chốc cô đã hòa nhập vào nhịp điệu của cuộc sống làng quê.\n\nElara cư trú trong một căn nhà nhỏ ở ngoại ô làng, những bức tường của nó được phủ đầy hoa hồng leo và khu vườn của nó là một bức tranh rực rỡ của màu sắc. Cô nhanh chóng trở thành gương mặt quen thuộc trong quảng trường làng, nơi cô lập một quầy hàng bán trang sức và đồ thủ công tự làm. Những tác phẩm của cô, tinh tế và phức tạp, phản ánh con mắt tinh tường của cô về vẻ đẹp và chi tiết, và chẳng bao lâu cô đã có được một lượng khách hàng trung thành trong số dân làng.\n\nKhi những ngày trôi qua thành tuần, Elara thấy mình bị thu hút bởi ông Harlan già và kho tàng kiến thức của ông về làng và lịch sử của nó. Cô thường đến thăm ngôi nhà của ông, mang theo bánh ngọt mới nướng hoặc một bó hoa dại, và ngồi nghe ông kể những câu chuyện về quá khứ của Willowbrook. Harlan, phần mình, rất vui vì sự đồng hành của Elara và sự quan tâm chân thành của cô đến những câu chuyện ông chia sẻ.\n\nMột ngày nọ, khi họ ngồi cùng nhau trên hiên nhà, Harlan bắt đầu kể cho Elara một câu chuyện đã được truyền qua nhiều thế hệ—một câu chuyện về tình yêu, mất mát và tinh thần bền bỉ của Willowbrook. Người ta nói rằng nhiều năm trước, trong một mùa đông đặc biệt khắc nghiệt, làng đã đứng trên bờ vực của sự tuyệt vọng. Mùa màng đã thất bại, và thực phẩm khan hiếm, và dân làng đối mặt với mối đe dọa thực sự của nạn đói.\n\nGiữa lúc khó khăn này, một cô gái trẻ tên Isolde đã nổi lên như một ngọn đèn hy vọng. Isolde, nổi tiếng với tấm lòng nhân hậu và sự quyết tâm không lay chuyển, đã tập hợp dân làng lại với nhau. Cô tổ chức những bữa ăn chung, nơi mọi người chia sẻ những gì ít ỏi mà họ có, và làm việc không ngừng nghỉ để đảm bảo rằng không ai bị đói. Những nỗ lực của cô không bị bỏ qua, và chẳng mấy chốc, dân làng bắt đầu làm theo gương của cô, cùng nhau hỗ trợ nhau trong lúc cần thiết.\n\nKhi Harlan kể lại câu chuyện của Isolde, Elara cảm thấy một sự kết nối sâu sắc với cô gái trẻ đã sống cách đây nhiều năm. Cô thấy trong hành động của Isolde sự phản chiếu của cùng một tinh thần đã đưa cô đến Willowbrook—một tinh thần bền bỉ, lòng trắc ẩn và cộng đồng. Lấy cảm hứng từ câu chuyện, Elara quyết định tôn vinh di sản của Isolde bằng cách tổ chức một lễ hội thu hoạch, một lễ kỷ niệm của sức mạnh và sự đoàn kết bền vững của làng.\n\nLễ hội, được tổ chức vào một ngày trong lành, trong suốt vào cuối tháng Mười, đã thành công rực rỡ. Dân làng từ mọi ngõ ngách đã cùng nhau chia sẻ trong sự phong phú của vụ mùa, thưởng thức một bữa tiệc gồm thịt nướng, rau củ theo mùa và những chiếc bánh mới nướng. Âm nhạc tràn ngập không khí, và trẻ em nhảy múa và chơi trò chơi, tiếng cười của chúng là minh chứng cho niềm vui đã trở lại với Willowbrook.\n\nKhi mặt trời lặn và lễ hội kết thúc, Elara đứng ở quảng trường làng, trái tim cô tràn đầy biết ơn và cảm giác thuộc về. Cô nhận ra rằng cô đã tìm thấy nhiều hơn chỉ là một ngôi nhà mới ở Willowbrook—cô đã tìm thấy một cộng đồng đã đón nhận cô với vòng tay rộng mở và một mục đích mang lại cho cuộc sống của cô ý nghĩa mới.\n\nÔng Harlan già, từ hiên nhà của mình, mỉm cười khi thấy ánh sáng trong mắt Elara. Ông biết rằng cô đã trở thành một phần của bức tranh phong phú của làng, câu chuyện của cô được dệt vào trong tấm vải lịch sử của Willowbrook. Và khi những năm tháng trôi qua, câu chuyện của Elara sẽ được kể và kể lại, là minh chứng cho tinh thần bền bỉ của một ngôi làng luôn tìm thấy sức mạnh trong sự đoàn kết và tình yêu.\n\nTrong những năm sau đó, Willowbrook tiếp tục thịnh vượng, cư dân của nó tiếp tục truyền lại những truyền thống và giá trị đã định hình cuộc sống của họ qua nhiều thế hệ. Quảng trường làng vẫn là một trung tâm sôi động, nơi những câu chuyện được chia sẻ và những mối quan hệ được hình thành. Và qua tất cả, tinh thần của Isolde, Harlan và Elara vẫn sống mãi, nhắc nhở rằng ngay cả khi đối mặt với khó khăn, sức mạnh của cộng đồng và lòng trắc ẩn có thể soi sáng con đường phía trước.\n\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.350858Z","iopub.execute_input":"2024-06-03T02:02:51.351262Z","iopub.status.idle":"2024-06-03T02:02:51.370849Z","shell.execute_reply.started":"2024-06-03T02:02:51.351184Z","shell.execute_reply":"2024-06-03T02:02:51.369568Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"text = processed(text)\ntext","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.372382Z","iopub.execute_input":"2024-06-03T02:02:51.372745Z","iopub.status.idle":"2024-06-03T02:02:51.390788Z","shell.execute_reply.started":"2024-06-03T02:02:51.372715Z","shell.execute_reply":"2024-06-03T02:02:51.389525Z"},"trusted":true},"execution_count":63,"outputs":[{"execution_count":63,"output_type":"execute_result","data":{"text/plain":"' trong một ngôi làng nhỏ, yên tĩnh nằm giữa những ngọn đồi uốn lượn và những khu rừng rậm rạp, cuộc sống mang một nhịp điệu bình yên nhưng sôi động đã tồn tại qua nhiều thế hệ. làng willowbrook là nơi thời gian dường như chậm lại và sự đơn giản của cuộc sống hàng ngày được cư dân của nó trân trọng. những con đường lát đá cuội được xếp hàng bởi những ngôi nhà nhỏ xinh đẹp, mỗi căn đều mang một vẻ độc đáo riêng, được trang trí với những bông hoa nở rộ và dây thường xuân leo lên tường.  trái tim của willowbrook là quảng trường làng, một trung tâm sôi động nơi dân làng tụ tập để trao đổi tin tức, mua bán hàng hóa và tham gia vào tinh thần cộng đồng định hình cuộc sống của họ. quảng trường là nơi có nhiều cửa hàng và quầy hàng khác nhau, mỗi nơi mang đến một cái nhìn thoáng qua về bức tranh văn hóa phong phú của làng. từ tiệm bánh, nơi hương thơm của bánh mì mới nướng lan tỏa trong không khí, đến lò rèn, nơi tiếng búa đập vào đe vang lên đều đặn, quảng trường là một bản giao hưởng của những hình ảnh, âm thanh và mùi hương.  trong số nhiều cư dân của willowbrook, có một nhân vật đặc biệt nổi bật—ông harlan già. harlan là một người có tuổi tác không xác định, khuôn mặt ông hằn sâu những nếp nhăn của vô số câu chuyện và trải nghiệm. ông đã sống ở làng từ khi mọi người còn nhớ, và sự hiện diện của ông là một phần không thể thiếu của willowbrook, giống như cây sồi cổ thụ đứng giữa quảng trường. ngôi nhà nhỏ của harlan, một nơi khiêm tốn nhưng ấm cúng, là kho tàng lịch sử của làng. những kệ sách đầy ắp sách vở, đồ trang trí và hiện vật kể lại những câu chuyện của thời kỳ đã qua, và khách ghé thăm thường bị cuốn hút bởi những câu chuyện của ông.  một buổi sáng mùa thu trong lành, khi những chiếc lá bắt đầu chuyển sang màu đỏ và vàng rực rỡ, harlan ngồi trên hiên nhà, cầm một tách trà nóng. đôi mắt ông, dù mờ đi vì tuổi tác, vẫn sáng lên với sự tò mò trẻ trung khi ông nhìn ngắm dân làng đi lại trong ngày. những đứa trẻ chơi trò đuổi bắt và trốn tìm, tiếng cười của chúng vang vọng trong không khí, trong khi những người nông dân mang về vụ thu hoạch cuối cùng, những chiếc xe chở đầy bí ngô, táo và bí đỏ.  vào buổi sáng đặc biệt này, một người mới đến willowbrook. một cô gái trẻ tên elara, với đôi mắt sáng và sự quyết tâm yên lặng, bước vào quảng trường làng. elara đã đi từ một thành phố xa xôi, tìm kiếm sự bình yên và một khởi đầu mới sau một loạt các sự kiện không may đã làm đảo lộn cuộc sống của cô. dân làng, luôn chào đón, đã đón tiếp cô bằng những nụ cười ấm áp và trái tim rộng mở, và chẳng mấy chốc cô đã hòa nhập vào nhịp điệu của cuộc sống làng quê.  elara cư trú trong một căn nhà nhỏ ở ngoại ô làng, những bức tường của nó được phủ đầy hoa hồng leo và khu vườn của nó là một bức tranh rực rỡ của màu sắc. cô nhanh chóng trở thành gương mặt quen thuộc trong quảng trường làng, nơi cô lập một quầy hàng bán trang sức và đồ thủ công tự làm. những tác phẩm của cô, tinh tế và phức tạp, phản ánh con mắt tinh tường của cô về vẻ đẹp và chi tiết, và chẳng bao lâu cô đã có được một lượng khách hàng trung thành trong số dân làng.  khi những ngày trôi qua thành tuần, elara thấy mình bị thu hút bởi ông harlan già và kho tàng kiến thức của ông về làng và lịch sử của nó. cô thường đến thăm ngôi nhà của ông, mang theo bánh ngọt mới nướng hoặc một bó hoa dại, và ngồi nghe ông kể những câu chuyện về quá khứ của willowbrook. harlan, phần mình, rất vui vì sự đồng hành của elara và sự quan tâm chân thành của cô đến những câu chuyện ông chia sẻ.  một ngày nọ, khi họ ngồi cùng nhau trên hiên nhà, harlan bắt đầu kể cho elara một câu chuyện đã được truyền qua nhiều thế hệ—một câu chuyện về tình yêu, mất mát và tinh thần bền bỉ của willowbrook. người ta nói rằng nhiều năm trước, trong một mùa đông đặc biệt khắc nghiệt, làng đã đứng trên bờ vực của sự tuyệt vọng. mùa màng đã thất bại, và thực phẩm khan hiếm, và dân làng đối mặt với mối đe dọa thực sự của nạn đói.  giữa lúc khó khăn này, một cô gái trẻ tên isolde đã nổi lên như một ngọn đèn hy vọng. isolde, nổi tiếng với tấm lòng nhân hậu và sự quyết tâm không lay chuyển, đã tập hợp dân làng lại với nhau. cô tổ chức những bữa ăn chung, nơi mọi người chia sẻ những gì ít ỏi mà họ có, và làm việc không ngừng nghỉ để đảm bảo rằng không ai bị đói. những nỗ lực của cô không bị bỏ qua, và chẳng mấy chốc, dân làng bắt đầu làm theo gương của cô, cùng nhau hỗ trợ nhau trong lúc cần thiết.  khi harlan kể lại câu chuyện của isolde, elara cảm thấy một sự kết nối sâu sắc với cô gái trẻ đã sống cách đây nhiều năm. cô thấy trong hành động của isolde sự phản chiếu của cùng một tinh thần đã đưa cô đến willowbrook—một tinh thần bền bỉ, lòng trắc ẩn và cộng đồng. lấy cảm hứng từ câu chuyện, elara quyết định tôn vinh di sản của isolde bằng cách tổ chức một lễ hội thu hoạch, một lễ kỷ niệm của sức mạnh và sự đoàn kết bền vững của làng.  lễ hội, được tổ chức vào một ngày trong lành, trong suốt vào cuối tháng mười, đã thành công rực rỡ. dân làng từ mọi ngõ ngách đã cùng nhau chia sẻ trong sự phong phú của vụ mùa, thưởng thức một bữa tiệc gồm thịt nướng, rau củ theo mùa và những chiếc bánh mới nướng. âm nhạc tràn ngập không khí, và trẻ em nhảy múa và chơi trò chơi, tiếng cười của chúng là minh chứng cho niềm vui đã trở lại với willowbrook.  khi mặt trời lặn và lễ hội kết thúc, elara đứng ở quảng trường làng, trái tim cô tràn đầy biết ơn và cảm giác thuộc về. cô nhận ra rằng cô đã tìm thấy nhiều hơn chỉ là một ngôi nhà mới ở willowbrook—cô đã tìm thấy một cộng đồng đã đón nhận cô với vòng tay rộng mở và một mục đích mang lại cho cuộc sống của cô ý nghĩa mới.  ông harlan già, từ hiên nhà của mình, mỉm cười khi thấy ánh sáng trong mắt elara. ông biết rằng cô đã trở thành một phần của bức tranh phong phú của làng, câu chuyện của cô được dệt vào trong tấm vải lịch sử của willowbrook. và khi những năm tháng trôi qua, câu chuyện của elara sẽ được kể và kể lại, là minh chứng cho tinh thần bền bỉ của một ngôi làng luôn tìm thấy sức mạnh trong sự đoàn kết và tình yêu.  trong những năm sau đó, willowbrook tiếp tục thịnh vượng, cư dân của nó tiếp tục truyền lại những truyền thống và giá trị đã định hình cuộc sống của họ qua nhiều thế hệ. quảng trường làng vẫn là một trung tâm sôi động, nơi những câu chuyện được chia sẻ và những mối quan hệ được hình thành. và qua tất cả, tinh thần của isolde, harlan và elara vẫn sống mãi, nhắc nhở rằng ngay cả khi đối mặt với khó khăn, sức mạnh của cộng đồng và lòng trắc ẩn có thể soi sáng con đường phía trước. '"},"metadata":{}}]},{"cell_type":"code","source":"\n# summarize_text(text, model_aug, tokenizer, chunk_size=500, overlap=2, device='cpu')","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.392265Z","iopub.execute_input":"2024-06-03T02:02:51.392618Z","iopub.status.idle":"2024-06-03T02:02:51.401779Z","shell.execute_reply.started":"2024-06-03T02:02:51.392590Z","shell.execute_reply":"2024-06-03T02:02:51.400513Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# import re\n# def split_into_chunks(text, max_words=800, overlap_sentences=2):\n\n#     sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n    \n#     chunks = []\n#     current_chunk = []\n#     current_word_count = 0\n    \n#     for sentence in sentences:\n#         word_count = len(sentence.split())\n#         if current_word_count + word_count <= max_words:\n#             current_chunk.append(sentence)\n#             current_word_count += word_count\n#         else:\n#             chunks.append(' '.join(current_chunk))\n#             current_chunk = current_chunk[-overlap_sentences:] + [sentence]\n#             current_word_count = sum(len(sent.split()) for sent in current_chunk)\n#     if current_chunk:\n#         chunks.append(' '.join(current_chunk))\n    \n#     return chunks","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.402919Z","iopub.execute_input":"2024-06-03T02:02:51.403292Z","iopub.status.idle":"2024-06-03T02:02:51.413580Z","shell.execute_reply.started":"2024-06-03T02:02:51.403257Z","shell.execute_reply":"2024-06-03T02:02:51.412443Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"def split_into_chunks(text, max_words=800, overlap_sentences=2):\n    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n    \n    chunks = []\n    current_chunk = []\n    current_word_count = 0\n    \n    for sentence in sentences:\n        word_count = len(sentence.split())\n        if current_word_count + word_count <= max_words:\n            current_chunk.append(sentence)\n            current_word_count += word_count\n        else:\n            if len(current_chunk) >= overlap_sentences:\n                overlap = current_chunk[-overlap_sentences:]\n            chunks.append(' '.join(current_chunk))\n            current_chunk = current_chunk[-overlap_sentences:] + [sentence]\n            current_word_count = sum(len(sent.split()) for sent in current_chunk)\n    if current_chunk:\n        if len(current_chunk) >= overlap_sentences:\n            overlap = current_chunk[-overlap_sentences:]\n        chunks.append(' '.join(current_chunk))\n    \n    return chunks\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.415181Z","iopub.execute_input":"2024-06-03T02:02:51.415644Z","iopub.status.idle":"2024-06-03T02:02:51.431324Z","shell.execute_reply.started":"2024-06-03T02:02:51.415607Z","shell.execute_reply":"2024-06-03T02:02:51.430262Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"c = split_into_chunks(text, 800, 2)\nc","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.432926Z","iopub.execute_input":"2024-06-03T02:02:51.433362Z","iopub.status.idle":"2024-06-03T02:02:51.448476Z","shell.execute_reply.started":"2024-06-03T02:02:51.433323Z","shell.execute_reply":"2024-06-03T02:02:51.447313Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"[' trong một ngôi làng nhỏ, yên tĩnh nằm giữa những ngọn đồi uốn lượn và những khu rừng rậm rạp, cuộc sống mang một nhịp điệu bình yên nhưng sôi động đã tồn tại qua nhiều thế hệ. làng willowbrook là nơi thời gian dường như chậm lại và sự đơn giản của cuộc sống hàng ngày được cư dân của nó trân trọng. những con đường lát đá cuội được xếp hàng bởi những ngôi nhà nhỏ xinh đẹp, mỗi căn đều mang một vẻ độc đáo riêng, được trang trí với những bông hoa nở rộ và dây thường xuân leo lên tường.  trái tim của willowbrook là quảng trường làng, một trung tâm sôi động nơi dân làng tụ tập để trao đổi tin tức, mua bán hàng hóa và tham gia vào tinh thần cộng đồng định hình cuộc sống của họ. quảng trường là nơi có nhiều cửa hàng và quầy hàng khác nhau, mỗi nơi mang đến một cái nhìn thoáng qua về bức tranh văn hóa phong phú của làng. từ tiệm bánh, nơi hương thơm của bánh mì mới nướng lan tỏa trong không khí, đến lò rèn, nơi tiếng búa đập vào đe vang lên đều đặn, quảng trường là một bản giao hưởng của những hình ảnh, âm thanh và mùi hương.  trong số nhiều cư dân của willowbrook, có một nhân vật đặc biệt nổi bật—ông harlan già. harlan là một người có tuổi tác không xác định, khuôn mặt ông hằn sâu những nếp nhăn của vô số câu chuyện và trải nghiệm. ông đã sống ở làng từ khi mọi người còn nhớ, và sự hiện diện của ông là một phần không thể thiếu của willowbrook, giống như cây sồi cổ thụ đứng giữa quảng trường. ngôi nhà nhỏ của harlan, một nơi khiêm tốn nhưng ấm cúng, là kho tàng lịch sử của làng. những kệ sách đầy ắp sách vở, đồ trang trí và hiện vật kể lại những câu chuyện của thời kỳ đã qua, và khách ghé thăm thường bị cuốn hút bởi những câu chuyện của ông.  một buổi sáng mùa thu trong lành, khi những chiếc lá bắt đầu chuyển sang màu đỏ và vàng rực rỡ, harlan ngồi trên hiên nhà, cầm một tách trà nóng. đôi mắt ông, dù mờ đi vì tuổi tác, vẫn sáng lên với sự tò mò trẻ trung khi ông nhìn ngắm dân làng đi lại trong ngày. những đứa trẻ chơi trò đuổi bắt và trốn tìm, tiếng cười của chúng vang vọng trong không khí, trong khi những người nông dân mang về vụ thu hoạch cuối cùng, những chiếc xe chở đầy bí ngô, táo và bí đỏ.  vào buổi sáng đặc biệt này, một người mới đến willowbrook. một cô gái trẻ tên elara, với đôi mắt sáng và sự quyết tâm yên lặng, bước vào quảng trường làng. elara đã đi từ một thành phố xa xôi, tìm kiếm sự bình yên và một khởi đầu mới sau một loạt các sự kiện không may đã làm đảo lộn cuộc sống của cô. dân làng, luôn chào đón, đã đón tiếp cô bằng những nụ cười ấm áp và trái tim rộng mở, và chẳng mấy chốc cô đã hòa nhập vào nhịp điệu của cuộc sống làng quê.  elara cư trú trong một căn nhà nhỏ ở ngoại ô làng, những bức tường của nó được phủ đầy hoa hồng leo và khu vườn của nó là một bức tranh rực rỡ của màu sắc. cô nhanh chóng trở thành gương mặt quen thuộc trong quảng trường làng, nơi cô lập một quầy hàng bán trang sức và đồ thủ công tự làm. những tác phẩm của cô, tinh tế và phức tạp, phản ánh con mắt tinh tường của cô về vẻ đẹp và chi tiết, và chẳng bao lâu cô đã có được một lượng khách hàng trung thành trong số dân làng.  khi những ngày trôi qua thành tuần, elara thấy mình bị thu hút bởi ông harlan già và kho tàng kiến thức của ông về làng và lịch sử của nó. cô thường đến thăm ngôi nhà của ông, mang theo bánh ngọt mới nướng hoặc một bó hoa dại, và ngồi nghe ông kể những câu chuyện về quá khứ của willowbrook. harlan, phần mình, rất vui vì sự đồng hành của elara và sự quan tâm chân thành của cô đến những câu chuyện ông chia sẻ.  một ngày nọ, khi họ ngồi cùng nhau trên hiên nhà, harlan bắt đầu kể cho elara một câu chuyện đã được truyền qua nhiều thế hệ—một câu chuyện về tình yêu, mất mát và tinh thần bền bỉ của willowbrook.',\n 'harlan, phần mình, rất vui vì sự đồng hành của elara và sự quan tâm chân thành của cô đến những câu chuyện ông chia sẻ.  một ngày nọ, khi họ ngồi cùng nhau trên hiên nhà, harlan bắt đầu kể cho elara một câu chuyện đã được truyền qua nhiều thế hệ—một câu chuyện về tình yêu, mất mát và tinh thần bền bỉ của willowbrook. người ta nói rằng nhiều năm trước, trong một mùa đông đặc biệt khắc nghiệt, làng đã đứng trên bờ vực của sự tuyệt vọng. mùa màng đã thất bại, và thực phẩm khan hiếm, và dân làng đối mặt với mối đe dọa thực sự của nạn đói.  giữa lúc khó khăn này, một cô gái trẻ tên isolde đã nổi lên như một ngọn đèn hy vọng. isolde, nổi tiếng với tấm lòng nhân hậu và sự quyết tâm không lay chuyển, đã tập hợp dân làng lại với nhau. cô tổ chức những bữa ăn chung, nơi mọi người chia sẻ những gì ít ỏi mà họ có, và làm việc không ngừng nghỉ để đảm bảo rằng không ai bị đói. những nỗ lực của cô không bị bỏ qua, và chẳng mấy chốc, dân làng bắt đầu làm theo gương của cô, cùng nhau hỗ trợ nhau trong lúc cần thiết.  khi harlan kể lại câu chuyện của isolde, elara cảm thấy một sự kết nối sâu sắc với cô gái trẻ đã sống cách đây nhiều năm. cô thấy trong hành động của isolde sự phản chiếu của cùng một tinh thần đã đưa cô đến willowbrook—một tinh thần bền bỉ, lòng trắc ẩn và cộng đồng. lấy cảm hứng từ câu chuyện, elara quyết định tôn vinh di sản của isolde bằng cách tổ chức một lễ hội thu hoạch, một lễ kỷ niệm của sức mạnh và sự đoàn kết bền vững của làng.  lễ hội, được tổ chức vào một ngày trong lành, trong suốt vào cuối tháng mười, đã thành công rực rỡ. dân làng từ mọi ngõ ngách đã cùng nhau chia sẻ trong sự phong phú của vụ mùa, thưởng thức một bữa tiệc gồm thịt nướng, rau củ theo mùa và những chiếc bánh mới nướng. âm nhạc tràn ngập không khí, và trẻ em nhảy múa và chơi trò chơi, tiếng cười của chúng là minh chứng cho niềm vui đã trở lại với willowbrook.  khi mặt trời lặn và lễ hội kết thúc, elara đứng ở quảng trường làng, trái tim cô tràn đầy biết ơn và cảm giác thuộc về. cô nhận ra rằng cô đã tìm thấy nhiều hơn chỉ là một ngôi nhà mới ở willowbrook—cô đã tìm thấy một cộng đồng đã đón nhận cô với vòng tay rộng mở và một mục đích mang lại cho cuộc sống của cô ý nghĩa mới.  ông harlan già, từ hiên nhà của mình, mỉm cười khi thấy ánh sáng trong mắt elara. ông biết rằng cô đã trở thành một phần của bức tranh phong phú của làng, câu chuyện của cô được dệt vào trong tấm vải lịch sử của willowbrook. và khi những năm tháng trôi qua, câu chuyện của elara sẽ được kể và kể lại, là minh chứng cho tinh thần bền bỉ của một ngôi làng luôn tìm thấy sức mạnh trong sự đoàn kết và tình yêu.  trong những năm sau đó, willowbrook tiếp tục thịnh vượng, cư dân của nó tiếp tục truyền lại những truyền thống và giá trị đã định hình cuộc sống của họ qua nhiều thế hệ. quảng trường làng vẫn là một trung tâm sôi động, nơi những câu chuyện được chia sẻ và những mối quan hệ được hình thành. và qua tất cả, tinh thần của isolde, harlan và elara vẫn sống mãi, nhắc nhở rằng ngay cả khi đối mặt với khó khăn, sức mạnh của cộng đồng và lòng trắc ẩn có thể soi sáng con đường phía trước. ']"},"metadata":{}}]},{"cell_type":"code","source":"len(c)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.450238Z","iopub.execute_input":"2024-06-03T02:02:51.450600Z","iopub.status.idle":"2024-06-03T02:02:51.462145Z","shell.execute_reply.started":"2024-06-03T02:02:51.450572Z","shell.execute_reply":"2024-06-03T02:02:51.461013Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}]},{"cell_type":"code","source":"c[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.463493Z","iopub.execute_input":"2024-06-03T02:02:51.463826Z","iopub.status.idle":"2024-06-03T02:02:51.475267Z","shell.execute_reply.started":"2024-06-03T02:02:51.463798Z","shell.execute_reply":"2024-06-03T02:02:51.474120Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"' trong một ngôi làng nhỏ, yên tĩnh nằm giữa những ngọn đồi uốn lượn và những khu rừng rậm rạp, cuộc sống mang một nhịp điệu bình yên nhưng sôi động đã tồn tại qua nhiều thế hệ. làng willowbrook là nơi thời gian dường như chậm lại và sự đơn giản của cuộc sống hàng ngày được cư dân của nó trân trọng. những con đường lát đá cuội được xếp hàng bởi những ngôi nhà nhỏ xinh đẹp, mỗi căn đều mang một vẻ độc đáo riêng, được trang trí với những bông hoa nở rộ và dây thường xuân leo lên tường.  trái tim của willowbrook là quảng trường làng, một trung tâm sôi động nơi dân làng tụ tập để trao đổi tin tức, mua bán hàng hóa và tham gia vào tinh thần cộng đồng định hình cuộc sống của họ. quảng trường là nơi có nhiều cửa hàng và quầy hàng khác nhau, mỗi nơi mang đến một cái nhìn thoáng qua về bức tranh văn hóa phong phú của làng. từ tiệm bánh, nơi hương thơm của bánh mì mới nướng lan tỏa trong không khí, đến lò rèn, nơi tiếng búa đập vào đe vang lên đều đặn, quảng trường là một bản giao hưởng của những hình ảnh, âm thanh và mùi hương.  trong số nhiều cư dân của willowbrook, có một nhân vật đặc biệt nổi bật—ông harlan già. harlan là một người có tuổi tác không xác định, khuôn mặt ông hằn sâu những nếp nhăn của vô số câu chuyện và trải nghiệm. ông đã sống ở làng từ khi mọi người còn nhớ, và sự hiện diện của ông là một phần không thể thiếu của willowbrook, giống như cây sồi cổ thụ đứng giữa quảng trường. ngôi nhà nhỏ của harlan, một nơi khiêm tốn nhưng ấm cúng, là kho tàng lịch sử của làng. những kệ sách đầy ắp sách vở, đồ trang trí và hiện vật kể lại những câu chuyện của thời kỳ đã qua, và khách ghé thăm thường bị cuốn hút bởi những câu chuyện của ông.  một buổi sáng mùa thu trong lành, khi những chiếc lá bắt đầu chuyển sang màu đỏ và vàng rực rỡ, harlan ngồi trên hiên nhà, cầm một tách trà nóng. đôi mắt ông, dù mờ đi vì tuổi tác, vẫn sáng lên với sự tò mò trẻ trung khi ông nhìn ngắm dân làng đi lại trong ngày. những đứa trẻ chơi trò đuổi bắt và trốn tìm, tiếng cười của chúng vang vọng trong không khí, trong khi những người nông dân mang về vụ thu hoạch cuối cùng, những chiếc xe chở đầy bí ngô, táo và bí đỏ.  vào buổi sáng đặc biệt này, một người mới đến willowbrook. một cô gái trẻ tên elara, với đôi mắt sáng và sự quyết tâm yên lặng, bước vào quảng trường làng. elara đã đi từ một thành phố xa xôi, tìm kiếm sự bình yên và một khởi đầu mới sau một loạt các sự kiện không may đã làm đảo lộn cuộc sống của cô. dân làng, luôn chào đón, đã đón tiếp cô bằng những nụ cười ấm áp và trái tim rộng mở, và chẳng mấy chốc cô đã hòa nhập vào nhịp điệu của cuộc sống làng quê.  elara cư trú trong một căn nhà nhỏ ở ngoại ô làng, những bức tường của nó được phủ đầy hoa hồng leo và khu vườn của nó là một bức tranh rực rỡ của màu sắc. cô nhanh chóng trở thành gương mặt quen thuộc trong quảng trường làng, nơi cô lập một quầy hàng bán trang sức và đồ thủ công tự làm. những tác phẩm của cô, tinh tế và phức tạp, phản ánh con mắt tinh tường của cô về vẻ đẹp và chi tiết, và chẳng bao lâu cô đã có được một lượng khách hàng trung thành trong số dân làng.  khi những ngày trôi qua thành tuần, elara thấy mình bị thu hút bởi ông harlan già và kho tàng kiến thức của ông về làng và lịch sử của nó. cô thường đến thăm ngôi nhà của ông, mang theo bánh ngọt mới nướng hoặc một bó hoa dại, và ngồi nghe ông kể những câu chuyện về quá khứ của willowbrook. harlan, phần mình, rất vui vì sự đồng hành của elara và sự quan tâm chân thành của cô đến những câu chuyện ông chia sẻ.  một ngày nọ, khi họ ngồi cùng nhau trên hiên nhà, harlan bắt đầu kể cho elara một câu chuyện đã được truyền qua nhiều thế hệ—một câu chuyện về tình yêu, mất mát và tinh thần bền bỉ của willowbrook.'"},"metadata":{}}]},{"cell_type":"code","source":"c[1]","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.476691Z","iopub.execute_input":"2024-06-03T02:02:51.478925Z","iopub.status.idle":"2024-06-03T02:02:51.487895Z","shell.execute_reply.started":"2024-06-03T02:02:51.478802Z","shell.execute_reply":"2024-06-03T02:02:51.486701Z"},"trusted":true},"execution_count":70,"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"'harlan, phần mình, rất vui vì sự đồng hành của elara và sự quan tâm chân thành của cô đến những câu chuyện ông chia sẻ.  một ngày nọ, khi họ ngồi cùng nhau trên hiên nhà, harlan bắt đầu kể cho elara một câu chuyện đã được truyền qua nhiều thế hệ—một câu chuyện về tình yêu, mất mát và tinh thần bền bỉ của willowbrook. người ta nói rằng nhiều năm trước, trong một mùa đông đặc biệt khắc nghiệt, làng đã đứng trên bờ vực của sự tuyệt vọng. mùa màng đã thất bại, và thực phẩm khan hiếm, và dân làng đối mặt với mối đe dọa thực sự của nạn đói.  giữa lúc khó khăn này, một cô gái trẻ tên isolde đã nổi lên như một ngọn đèn hy vọng. isolde, nổi tiếng với tấm lòng nhân hậu và sự quyết tâm không lay chuyển, đã tập hợp dân làng lại với nhau. cô tổ chức những bữa ăn chung, nơi mọi người chia sẻ những gì ít ỏi mà họ có, và làm việc không ngừng nghỉ để đảm bảo rằng không ai bị đói. những nỗ lực của cô không bị bỏ qua, và chẳng mấy chốc, dân làng bắt đầu làm theo gương của cô, cùng nhau hỗ trợ nhau trong lúc cần thiết.  khi harlan kể lại câu chuyện của isolde, elara cảm thấy một sự kết nối sâu sắc với cô gái trẻ đã sống cách đây nhiều năm. cô thấy trong hành động của isolde sự phản chiếu của cùng một tinh thần đã đưa cô đến willowbrook—một tinh thần bền bỉ, lòng trắc ẩn và cộng đồng. lấy cảm hứng từ câu chuyện, elara quyết định tôn vinh di sản của isolde bằng cách tổ chức một lễ hội thu hoạch, một lễ kỷ niệm của sức mạnh và sự đoàn kết bền vững của làng.  lễ hội, được tổ chức vào một ngày trong lành, trong suốt vào cuối tháng mười, đã thành công rực rỡ. dân làng từ mọi ngõ ngách đã cùng nhau chia sẻ trong sự phong phú của vụ mùa, thưởng thức một bữa tiệc gồm thịt nướng, rau củ theo mùa và những chiếc bánh mới nướng. âm nhạc tràn ngập không khí, và trẻ em nhảy múa và chơi trò chơi, tiếng cười của chúng là minh chứng cho niềm vui đã trở lại với willowbrook.  khi mặt trời lặn và lễ hội kết thúc, elara đứng ở quảng trường làng, trái tim cô tràn đầy biết ơn và cảm giác thuộc về. cô nhận ra rằng cô đã tìm thấy nhiều hơn chỉ là một ngôi nhà mới ở willowbrook—cô đã tìm thấy một cộng đồng đã đón nhận cô với vòng tay rộng mở và một mục đích mang lại cho cuộc sống của cô ý nghĩa mới.  ông harlan già, từ hiên nhà của mình, mỉm cười khi thấy ánh sáng trong mắt elara. ông biết rằng cô đã trở thành một phần của bức tranh phong phú của làng, câu chuyện của cô được dệt vào trong tấm vải lịch sử của willowbrook. và khi những năm tháng trôi qua, câu chuyện của elara sẽ được kể và kể lại, là minh chứng cho tinh thần bền bỉ của một ngôi làng luôn tìm thấy sức mạnh trong sự đoàn kết và tình yêu.  trong những năm sau đó, willowbrook tiếp tục thịnh vượng, cư dân của nó tiếp tục truyền lại những truyền thống và giá trị đã định hình cuộc sống của họ qua nhiều thế hệ. quảng trường làng vẫn là một trung tâm sôi động, nơi những câu chuyện được chia sẻ và những mối quan hệ được hình thành. và qua tất cả, tinh thần của isolde, harlan và elara vẫn sống mãi, nhắc nhở rằng ngay cả khi đối mặt với khó khăn, sức mạnh của cộng đồng và lòng trắc ẩn có thể soi sáng con đường phía trước. '"},"metadata":{}}]},{"cell_type":"code","source":"x = []\nfor i in c:\n    tmp = summarize(i, model_aug, tokenizer, num_beams=4)\n    x.append(tmp)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:02:51.489315Z","iopub.execute_input":"2024-06-03T02:02:51.489675Z","iopub.status.idle":"2024-06-03T02:03:25.330269Z","shell.execute_reply.started":"2024-06-03T02:02:51.489647Z","shell.execute_reply":"2024-06-03T02:03:25.329082Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"c = 1\nfor i in x:\n    print(\"đoạn: \", c)\n    print(i)\n    c = c+1","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:25.331812Z","iopub.execute_input":"2024-06-03T02:03:25.332294Z","iopub.status.idle":"2024-06-03T02:03:25.339422Z","shell.execute_reply.started":"2024-06-03T02:03:25.332252Z","shell.execute_reply":"2024-06-03T02:03:25.338136Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"đoạn:  1\nlàng willowbrook là một ngôi làng nhỏ với những con đường lát đá cuội và quảng trường sôi động. trong số cư dân của willowbrook có harlan già với kho tàng lịch sử phong phú với nhiều cửa hàng và quầy hàng. harlan là người sống trong một ngôi làng nhỏ với nhiều cửa hàng và quầy hàng. ông sống trong một ngôi làng nhỏ với nhiều cửa hàng và quầy hàng. ông sống trong một ngôi làng nhỏ với nhiều cửa hàng và quầy hàng. ông sống trong một ngôi làng nhỏ với nhiều cửa hàng và quầy hàng. ông sống trong một ngôi làng nhỏ với nhiều cửa hàng và quầy hàng. elara là một cô gái trẻ sống trong một ngôi nhà nhỏ ở ngoại ô. elara là một cô gái trẻ sống trong ngôi nhà nhỏ với harlan và kho tàng lịch sử của willowbrook được lưu truyền qua nhiều thế hệ.\nđoạn:  2\nelara chia sẻ câu chuyện về tình yêu mất mát và tinh thần bền bỉ của willowbrook thông qua lễ hội thu hoạch và lễ kỷ niệm về sức mạnh của cộng đồng.\n","output_type":"stream"}]},{"cell_type":"code","source":"z = ''.join(x)\nz","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:25.340770Z","iopub.execute_input":"2024-06-03T02:03:25.341382Z","iopub.status.idle":"2024-06-03T02:03:25.353843Z","shell.execute_reply.started":"2024-06-03T02:03:25.341347Z","shell.execute_reply":"2024-06-03T02:03:25.352645Z"},"trusted":true},"execution_count":73,"outputs":[{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"'làng willowbrook là một ngôi làng nhỏ với những con đường lát đá cuội và quảng trường sôi động. trong số cư dân của willowbrook có harlan già với kho tàng lịch sử phong phú với nhiều cửa hàng và quầy hàng. harlan là người sống trong một ngôi làng nhỏ với nhiều cửa hàng và quầy hàng. ông sống trong một ngôi làng nhỏ với nhiều cửa hàng và quầy hàng. ông sống trong một ngôi làng nhỏ với nhiều cửa hàng và quầy hàng. ông sống trong một ngôi làng nhỏ với nhiều cửa hàng và quầy hàng. ông sống trong một ngôi làng nhỏ với nhiều cửa hàng và quầy hàng. elara là một cô gái trẻ sống trong một ngôi nhà nhỏ ở ngoại ô. elara là một cô gái trẻ sống trong ngôi nhà nhỏ với harlan và kho tàng lịch sử của willowbrook được lưu truyền qua nhiều thế hệ.elara chia sẻ câu chuyện về tình yêu mất mát và tinh thần bền bỉ của willowbrook thông qua lễ hội thu hoạch và lễ kỷ niệm về sức mạnh của cộng đồng.'"},"metadata":{}}]},{"cell_type":"code","source":"def post_processing(text):\n    sentences = re.split(r'(?<=[.!?])\\s*', text)\n    for i in range(len(sentences)):\n        if sentences[i]:\n            sentences[i] = sentences[i][0].upper() + sentences[i][1:]\n    text = \" \".join(sentences)\n    return text","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:25.355590Z","iopub.execute_input":"2024-06-03T02:03:25.356006Z","iopub.status.idle":"2024-06-03T02:03:25.371985Z","shell.execute_reply.started":"2024-06-03T02:03:25.355967Z","shell.execute_reply":"2024-06-03T02:03:25.370602Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"final = post_processing(z)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:25.373971Z","iopub.execute_input":"2024-06-03T02:03:25.374467Z","iopub.status.idle":"2024-06-03T02:03:25.385200Z","shell.execute_reply.started":"2024-06-03T02:03:25.374425Z","shell.execute_reply":"2024-06-03T02:03:25.383951Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"def display(text):\n    sentences = re.split(r'(?<=[.!?])\\s*', text)\n    unique_sentences = list(dict.fromkeys(sentences[:-1]))\n    for sentence in unique_sentences:\n        print(f\"• {sentence}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:25.386957Z","iopub.execute_input":"2024-06-03T02:03:25.387486Z","iopub.status.idle":"2024-06-03T02:03:25.400597Z","shell.execute_reply.started":"2024-06-03T02:03:25.387368Z","shell.execute_reply":"2024-06-03T02:03:25.399413Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"display(final)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:25.406349Z","iopub.execute_input":"2024-06-03T02:03:25.406812Z","iopub.status.idle":"2024-06-03T02:03:25.416639Z","shell.execute_reply.started":"2024-06-03T02:03:25.406780Z","shell.execute_reply":"2024-06-03T02:03:25.415366Z"},"trusted":true},"execution_count":77,"outputs":[{"name":"stdout","text":"• Làng willowbrook là một ngôi làng nhỏ với những con đường lát đá cuội và quảng trường sôi động.\n• Trong số cư dân của willowbrook có harlan già với kho tàng lịch sử phong phú với nhiều cửa hàng và quầy hàng.\n• Harlan là người sống trong một ngôi làng nhỏ với nhiều cửa hàng và quầy hàng.\n• Ông sống trong một ngôi làng nhỏ với nhiều cửa hàng và quầy hàng.\n• Elara là một cô gái trẻ sống trong một ngôi nhà nhỏ ở ngoại ô.\n• Elara là một cô gái trẻ sống trong ngôi nhà nhỏ với harlan và kho tàng lịch sử của willowbrook được lưu truyền qua nhiều thế hệ.\n• Elara chia sẻ câu chuyện về tình yêu mất mát và tinh thần bền bỉ của willowbrook thông qua lễ hội thu hoạch và lễ kỷ niệm về sức mạnh của cộng đồng.\n","output_type":"stream"}]},{"cell_type":"code","source":"# def pipeline(url):\n#     trans, sub = get_subtitles(url)\n#     sub = restore_punctuation(sub)\n#     vie_sub = translate_long(sub)\n#     vie_sub = processed(vie_sub)\n#     chunks = split_into_chunks(vie_sub, 700, 3)\n#     sum_para = []\n#     for i in chunks:\n#         tmp = summarize(i, model_aug, tokenizer, num_beams=4)\n#         sum_para.append(tmp)\n#     suma = ''.join(sum_para)\n#     del sub, vie_sub, sum_para, chunks\n#     suma = post_processing(suma)\n#     display(suma)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:25.418339Z","iopub.execute_input":"2024-06-03T02:03:25.419270Z","iopub.status.idle":"2024-06-03T02:03:25.432988Z","shell.execute_reply.started":"2024-06-03T02:03:25.419191Z","shell.execute_reply":"2024-06-03T02:03:25.431765Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"import time\n\n\ndef pipeline(url, model, tokenizer):\n    start_time = time.time()  # Thời điểm bắt đầu\n\n    trans, sub = get_subtitles(url)\n    sub = restore_punctuation(sub)\n    print(\"Time elapsed for get_subtitles:\", time.time() - start_time)  # Thời gian đã trôi qua từ khi bắt đầu\n\n    start_time = time.time()  # Thời điểm bắt đầu lại\n\n    vie_sub = translate_long(sub)\n    vie_sub = processed(vie_sub)\n    print(\"Time elapsed for processing subtitles:\", time.time() - start_time)  # Thời gian đã trôi qua từ khi bắt đầu\n\n    start_time = time.time()  # Thời điểm bắt đầu lại\n\n    chunks = split_into_chunks(vie_sub, 700, 2)\n    sum_para = []\n    for i in chunks:\n        tmp = summarize(i, model, tokenizer, num_beams=4)\n        sum_para.append(tmp)\n    suma = ''.join(sum_para)\n    print(\"Time elapsed for summarization:\", time.time() - start_time)  # Thời gian đã trôi qua từ khi bắt đầu\n\n    del sub, vie_sub, sum_para, chunks\n\n    start_time = time.time()  # Thời điểm bắt đầu lại\n\n    suma = post_processing(suma)\n    print(\"Time elapsed for post processing:\", time.time() - start_time)  # Thời gian đã trôi qua từ khi bắt đầu\n\n    # Hiển thị kết quả\n    display(suma)\n\n    # Trả về kết quả\n    return suma","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:13:48.336113Z","iopub.execute_input":"2024-06-03T02:13:48.336659Z","iopub.status.idle":"2024-06-03T02:13:48.348479Z","shell.execute_reply.started":"2024-06-03T02:13:48.336625Z","shell.execute_reply":"2024-06-03T02:13:48.347039Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"# pipeline('https://www.youtube.com/watch?v=3zhwbwKwcJ0')","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:25.450147Z","iopub.execute_input":"2024-06-03T02:03:25.450529Z","iopub.status.idle":"2024-06-03T02:03:25.462690Z","shell.execute_reply.started":"2024-06-03T02:03:25.450498Z","shell.execute_reply":"2024-06-03T02:03:25.461447Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"url = 'https://www.youtube.com/watch?v=SndHALawoag'\ntrans, sub = get_subtitles(url)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:25.464569Z","iopub.execute_input":"2024-06-03T02:03:25.465578Z","iopub.status.idle":"2024-06-03T02:03:25.919520Z","shell.execute_reply.started":"2024-06-03T02:03:25.465526Z","shell.execute_reply":"2024-06-03T02:03:25.918279Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"sub","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:25.920909Z","iopub.execute_input":"2024-06-03T02:03:25.921322Z","iopub.status.idle":"2024-06-03T02:03:25.929399Z","shell.execute_reply.started":"2024-06-03T02:03:25.921286Z","shell.execute_reply":"2024-06-03T02:03:25.928057Z"},"trusted":true},"execution_count":82,"outputs":[{"execution_count":82,"output_type":"execute_result","data":{"text/plain":"'Hi there!\\nToday we\\xa0\\xa0 are discussing the Swin Transformer.\\nSwin stands here for Shifted WINdows\\xa0\\xa0 and is basically a vision transformer variant but\\xa0\\nwith a hierarchical way of processing the image. So, if you are curious about\\xa0\\nthis vision transformer beast,\\xa0\\xa0 reportedly beating many benchmarks, grab a cup of coffee because it\\xa0\\nis time for an AI Coffee Break! Speaking of motivation for the Swin Transformer:\\xa0 Reading this part of the abstract\\xa0\\ntriggered me a little bit:\\xa0 It is about the “Challenges in adapting\\xa0\\nTransformer from language to vision\". And the authors say, they \"arise from\\xa0\\ndifferences between the two domains,\\xa0\\xa0 such as large variations in the scale\\xa0\\xa0 of visual entities and the high resolution of\\xa0\\npixels in images compared to words in text.” This is such a computer vision\\xa0\\nresearcher thing to say!\\xa0\\xa0 Everything is big data if you are brave enough. Words in text can become too many too if one wants\\xa0\\xa0 to handle a complete Dostoyevsky\\xa0\\nnovel as one single data point. But yes, point taken from the authors here, that\\xa0\\nthere are more images in this world than novels, so funnily, while transformers with linearly\\xa0\\nscaling attention can handle entire novels as\\xa0\\xa0 one sequence, there are not enough novels written\\xa0\\nto create significant datasets in this way, so yeah... text transformers usually\\xa0\\nwork with smaller sequences and text\\xa0\\xa0 is usually processed at a sentence-level. Anyway, back to the Swin Transformer here. It is based on ViT and to remember\\xa0\\nhow the Vision Transformer works,\\xa0\\xa0 you can check out our video on this. Because here, we are going\\xa0\\nto put it into a nutshell:\\xa0\\xa0 the image is decomposed into 16x16 pixel patches,\\xa0 then these patches are transformed into\\xa0\\npatch vectors by a linear transformation. These patch vectors combined\\xa0\\nwith positional embeddings,\\xa0 are processed by a transformer in the same\\xa0\\nway in which the transformer processes\\xa0\\xa0 word vectors, which we also\\xa0\\ndiscussed in a previous video. But, there is a problem with the\\xa0\\nvision transformer that the authors\\xa0\\xa0 here try to alleviate with the Swin Transfomer: the problem is related to\\xa0\\nthe extraction of patches;\\xa0\\xa0 a step which is particular to images, not to text. If the image is let’s say… 256x256 pixels,\\nthen extracting 16x16 pixel patches\\xa0\\xa0 would lead to 16 patches, thus 16\\xa0\\nimage vectors would form a sequence. But an image of 1920x1920 pixels would\\xa0\\nalready lead to 120 image vectors,\\xa0\\xa0 which is still ok with bigger\\xa0\\nand bigger GPUs, of course. And if we do this to solve tasks\\xa0\\nwhere looking at 16x16 pixel patches\\xa0\\xa0 is not too coarse, then ViT is still ok. And this is the case for tasks that are, in\\xa0\\na sense, summarizing the image, like it’s the\\xa0\\xa0 case with image classification, where the goal\\xa0\\nis to predict one label for the entire image. Analyzing the image through big\\xa0\\npatches is not that problematic here. But there are tasks, where one really needs\\xa0\\ndetailed information at pixel-level, not patches. Such a task is semantic segmentation where\\xa0\\nthe algorithm needs to decide for each\\xa0\\xa0 single pixel in the image,\\xa0\\nwhat class this belongs to. In this case, 16 by 16 pixel patches are way\\xa0\\nto big. So ideally, we would like to handle\\xa0\\xa0 every pixel as a token, but this\\xa0\\nwould quickly become infeasible: For example, a 256 by 256 pixel\\xa0\\nimage would already require a\\xa0\\xa0 transformer handling sequence\\xa0\\nlengths of over 63,000 tokens; a Full HD image of 1920x1080 would require\\xa0\\nalready a sequence length of over 2 million! This is not scalable, and we\\xa0\\ncan completely forget scaling up\\xa0\\xa0 native deep learning processing to 4K images\\xa0\\n– who is crazy enough to even want to do that? Anyway, so now we’ve seen that ViT\\xa0\\nfirst splits up the image into patches,\\xa0\\xa0 in order to keep the sequence\\xa0\\nlength within computational bounds. But this is problematic for tasks that\\xa0\\nrequire detailed processing of every pixel. So, let’s look at how the Swin\\xa0\\nTransformer wants to tackle this problem: The Swin Transformer still relies on patches,\\nbut instead of choosing one size and sticking\\xa0\\xa0 with it, the Swin Transformer first starts with\\xa0\\nsmall patches for the first Transformer layer, then merges them into bigger ones\\xa0\\nin the deeper Transformer layers. This reminds us of something, Ms. Coffee Bean… Yeah, of U-Net and convolutions.\\xa0\\nNow, let’s not get distracted here. So the Swin Transformer takes in the image\\nAnd splits the image into 4x4 patches. Each patch is still a colored image,\\xa0\\xa0 with three channels. So a patch has a\\xa0\\n4x4x3 equals 48 feature dimensionality, which is then linearly transformed\\xa0\\nto a dimensionality C of your choice. So the only difference to ViT so\\xa0\\nfar is that the patches are smaller. But what about this size C, and what does it mean? Well, C determines the capacity, or\\xa0\\nthe size of your Transformer model. So you maybe know that there is a BERT-base\\xa0\\xa0 text model, which has a dimensionality\\xa0\\nof 768 for the vector representations? Well, in that case, C is 768.\\nThere is also a BERT large with C=1024. C is the capacity of the\\xa0\\nmodel because it determines\\xa0 the parameter size or the amount of hidden\\xa0\\nunits in the fully connected layers over here. Just to get an impression about the\\xa0\\nSwin Transformer, for Swin-Tiny,\\xa0\\xa0 C is 96 and 192 for Swin-Large. But where were we? At the Swin Transformer that\\xa0\\xa0 has divided the image into\\xa0\\ninitial 4 by 4 pixel patches and a linear transformation converting\\xa0\\neach patch into a C-dimensional vector. Transformer blocks process these patch vectors but\\nnot with the usual quadratically scaling\\xa0\\xa0 attention, but with the Shifted Window based\\xa0\\nSelf-Attention introduced by the authors. This is just a fancy name for\\xa0\\nsaying that the attention span is\\xa0\\xa0 limited over M patches (here two). So now in self attention, one patch does\\xa0\\nnot communicate with all other patches,\\xa0\\xa0 but only with M neighbors. I am so sure that I saw this\\xa0\\nwindow limited self-attention\\xa0\\xa0 before in another paper under a different name. Ms. Coffee Bean, do you remember where?\\xa0\\nNo. Oh, I’ll ask the audience then. If you saw this kind of attention before,\\xa0\\xa0 or something very similar to it, then\\xa0\\nplease let us know in the comments where. It was probably an NLP paper. Ok, in any case,\\xa0\\xa0 the limited attention window basically simulates\\xa0\\nfor let’s say, this first image patch token here, that the rest of the sequence that is not in\\xa0\\nits M neighborhood, basically disappeared. This means that instead a quadratically scaling\\xa0\\nattention computation with the sequence length,\\xa0 we now have something linear for small M. Great, so now it is time to move further\\xa0\\nto the next layer in the hierarchy here: The output of a sequence of N patch vectors\\xa0\\xa0 is of course again N vectors because the\\xa0\\ntransformer is sort-of an autoencoder. Now the output is merged by\\xa0\\na so-called “merging layer”.\\xa0 This concatenates the vectors of\\xa0\\ngroups of 2x2 neighboring patches\\xa0\\xa0 (in the image, not in the sequence as it\\xa0\\nis quite simplistically visualized here), so from 4 of these C-dimensional vectors,\\xa0\\xa0 we now have one 4xC dimensional vector\\nand this is passed through\\xa0\\xa0 a linear layer which is basically a linear\\xa0\\ndimensionality reducer from 4C to 2C dimensions. Ok, let’s simplify here a bit: If in the beginning\\xa0\\nwe had 4 patches, now we would have 1 patch, but note that the hidden representation has been\\xa0\\xa0 doubled in order to increase the capacity\\xa0\\nto capture information from a larger region. And then again, the whole process repeats:\\xa0 a limited attention-span transformer module is\\xa0\\nprocessing the output and this goes on and on. But each time the attention window is\\xa0\\nshifted with respect to the previous layer. So if in the first layer, the attention was\\xa0\\nlimited to neighborhoods of these regions,\\xa0\\xa0 in the next layer the regions are\\xa0\\nshifted (like in strided convolution) such that patches that landed into\\xa0\\nseparate windows in layer one and could\\xa0\\xa0 not communicate, can now communicate at layer two. Then the resulting patch vectors are\\xa0\\nagain merged by the merging layer\\xa0 and the whole hierarchical procedure is repeated\\xa0\\ndepending on the chosen number of layers\\xa0 or until no merging is possible\\xa0\\nanymore, and this was basically it. Ms. Coffee Bean has two more comments. First, regarding the positional embeddings for the\\xa0\\nSwin Transformer, we should say that in principle,\\xa0 all kinds of positional embeddings are applicable. But the authors found that positional\\xa0\\nembeddings which are directly added to\\xa0\\xa0 the vector representation of the tokens\\xa0\\nare not working as well as the relative\\xa0\\xa0 position bias in self-attention, a method very\\xa0\\nsimilar to what we presented in this video. And secondly: how good is the Swin Transformer? Well, it outperforms ViT and\\xa0\\nDeiT on image classification,\\xa0\\xa0 object detection and semantic segmentation. It’s small objects in object detection where\\xa0\\nwe would expect to see improvements with the\\xa0\\xa0 Swin Transformer and of course, in semantic\\xa0\\nsegmentation where every pixel must be labelled. However, make up your own mind about the\\xa0\\ncomparisons with the state-of-the art,\\xa0\\xa0 because, you know, like\\xa0\\nmost of the papers nowadays,\\xa0\\xa0 the baselines are not necessarily\\xa0\\ntuned to be the strongest. Look at semantic segmentation in Table 3: The\\xa0\\nSwin Transformer implementation is compared\\xa0\\xa0 to the DeiT transformer counterpart\\xa0\\nbut only in it’s smallest version. A single measurement for one configuration of DeiT\\xa0\\xa0 is not enough to see how this all\\xa0\\nbehaves when scaling the model,\\xa0\\xa0 especially when in terms of number of parameters,\\xa0\\nDeiT small is even smaller than Swin Tiny. Not really a worthy opponent\\xa0\\nfor Swin-Large here, right?\\xa0\\xa0 Make up your own mind about this and let\\xa0\\nus know in the comments what you think. Which vision transformer variant is the one that\\xa0\\ndetermined you to leave the ViT model and use\\xa0\\xa0 another variant (if any)? Ms. Coffee\\xa0\\nBean would be curious about that. If you liked this content, do not forget\\xa0\\nto leave a like to help with the YouTube\\xa0\\xa0 algorithm. Ms. Coffee Bean, I am curious to know\\xa0\\nif THE YT Algorithm is transformer-based or not. Ms. Coffee Bean? Where are you going, I did not end the video yet. Well, I guess it ended now. Okay bye!.'"},"metadata":{}}]},{"cell_type":"code","source":"sub = restore_punctuation(sub)\nsub","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:25.931191Z","iopub.execute_input":"2024-06-03T02:03:25.931586Z","iopub.status.idle":"2024-06-03T02:03:54.943160Z","shell.execute_reply.started":"2024-06-03T02:03:25.931556Z","shell.execute_reply":"2024-06-03T02:03:54.939435Z"},"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"'Hi there, Today we are discussing the Swin Transformer. Swin stands here for Shifted WINdows and is basically a vision transformer variant, but with a hierarchical way of processing the image. So if you are curious about this vision transformer beast reportedly beating many benchmarks, grab a cup of coffee, because it is time for an AI Coffee Break. Speaking of motivation for the Swin Transformer, Reading this part of the abstract triggered me a little bit. It is about the “Challenges in adapting Transformer from language to vision\", And the authors say they \"arise from differences between the two domains, such as large variations in the scale of visual entities and the high resolution of pixels in images compared to words in text”. This is such a computer vision researcher thing to say. Everything is big data if you are brave enough. Words in text can become too many too if one wants to handle a complete Dostoyevsky novel as one single data point. But yes, point taken from the authors here that there are more images in this world than novels. so, funnily, while transformers with linearly scaling attention can handle entire novels as one sequence, there are not enough novels written to create significant datasets in this way. so yeah, text transformers usually work with smaller sequences and text is usually processed at a sentence-level. Anyway, back to the Swin Transformer. here It is based on ViT and to remember how the Vision Transformer works, you can check out our video on this, Because here we are going to put it into a nutshell: the image is decomposed into 16x16 pixel patches. then these patches are transformed into patch vectors by a linear transformation. These patch vectors, combined with positional embeddings, are processed by a transformer in the same way in which the transformer processes word vectors, which we also discussed in a previous video. But there is a problem with the vision transformer that the authors here try to alleviate with the Swin Transfomer. the problem is related to the extraction of patches, a step which is particular to images, not to text. If the image is, let’s say… 256x256 pixels, then extracting 16x16 pixel patches would lead to 16 patches. thus 16 image vectors would form a sequence. But an image of 1920x1920 pixels would already lead to 120 image vectors, which is still ok, with bigger and bigger GPUs, of course. And if we do this to solve tasks where looking at 16x16 pixel patches is not too coarse, then ViT is still ok. And this is the case for tasks that are in a sense summarizing the image, like it’s the case with image classification, where the goal is to predict one label for the entire image. Analyzing the image through big patches is not that problematic here, But there are tasks where one really needs detailed information at pixel-level, not patches. Such a task is semantic segmentation, where the algorithm needs to decide for each single pixel in the image what class this belongs to. In this case, 16 by 16 pixel patches are way to big. So ideally we would like to handle every pixel as a token, but this would quickly become infeasible. For example, a 256 by 256 pixel image would already require a transformer handling sequence lengths of over 63,000 tokens. a Full HD image of 1920x1080 would require already a sequence length of over 2 million. This is not scalable, and we can completely forget scaling up native deep learning processing to 4K images – who is crazy enough to even want to do that, Anyway? so now we’ve seen that ViT first splits up the image into patches in order to keep the sequence length within computational bounds, But this is problematic for tasks that require detailed processing of every pixel. So let’s look at how the Swin Transformer wants to tackle this problem. The Swin Transformer still relies on patches, but instead of choosing one size and sticking with it, the Swin Transformer first starts with small patches for the first Transformer layer, then merges them into bigger ones in the deeper Transformer layers. This reminds us of something Ms Coffee Bean… Yeah, of U-Net and convolutions. Now let’s not get distracted here. So the Swin Transformer takes in the image And splits the image into 4x4 patches. Each patch is still a colored image with three channels. So a patch has a 4x4x3 equals 48 feature dimensionality, which is then linearly transformed to a dimensionality C of your choice. So the only difference to ViT so far is that the patches are smaller. But what about this size C? and what does it mean? Well, C determines the capacity or the size of your Transformer model. So you maybe know that there is a BERT-base text model which has a dimensionality of 768 for the vector representations. Well, in that case C is 768.. There is also a BERT large with C=1024.. C is the capacity of the model, because it determines the parameter size or the amount of hidden units in the fully connected layers. over here, Just to get an impression about the Swin Transformer: for Swin-Tiny, C is 96 and 192 for Swin-Large. But where were we At the Swin Transformer that has divided the image into initial 4 by 4 pixel patches and a linear transformation converting each patch into a C-dimensional vector. Transformer blocks process these patch vectors, but not with the usual quadratically scaling attention, but with the Shifted Window based Self-Attention introduced by the authors. This is just a fancy name for saying that the attention span is limited over M patches (here two). So now in self attention, one patch does not communicate with all other patches, but only with M neighbors. I am so sure that I saw this window limited self-attention before in another paper under a different name, Ms Coffee Bean. do you remember where? No, Oh, I’ll ask the audience then. If you saw this kind of attention before, or something very similar to it, then please let us know in the comments where It was probably an NLP paper. Ok, in any case, the limited attention window basically simulates- for, let’s say, this first image patch token here- that the rest of the sequence that is not in its M neighborhood basically disappeared. This means that instead a quadratically scaling attention computation with the sequence length, we now have something linear for small M, Great. so now it is time to move further to the next layer in the hierarchy. here The output of a sequence of N patch vectors is of course again N vectors, because the transformer is sort-of an autoencoder. Now the output is merged by a so-called “merging layer”. This concatenates the vectors of groups of 2x2 neighboring patches (in the image, not in the sequence as it is quite simplistically visualized here). so from 4 of these C-dimensional vectors we now have one 4xC dimensional vector, and this is passed through a linear layer which is basically a linear dimensionality reducer from 4C to 2C dimensions. Ok, let’s simplify here a bit. If in the beginning we had 4 patches, now we would have 1 patch, but note that the hidden representation has been doubled in order to increase the capacity to capture information from a larger region. And then again the whole process repeats. a limited attention-span transformer module is processing the output, and this goes on and on. But each time the attention window is shifted with respect to the previous layer. So if in the first layer the attention was limited to neighborhoods of these regions, in the next layer the regions are shifted (like in strided convolution) such that patches that landed into separate windows in layer one and could not communicate can now communicate at layer two. Then the resulting patch vectors are again merged by the merging layer and the whole hierarchical procedure is repeated, depending on the chosen number of layers or until no merging is possible anymore. and this was basically it. Ms Coffee Bean has two more comments. First, regarding the positional embeddings for the Swin Transformer, we should say that, in principle, all kinds of positional embeddings are applicable, But the authors found that positional embeddings which are directly added to the vector representation of the tokens are not working, as well as the relative position bias in self-attention, a method very similar to what we presented in this video. And secondly, how good is the Swin Transformer? Well, it outperforms ViT and DeiT on image classification, object detection and semantic segmentation. It’s small objects in object detection where we would expect to see improvements with the Swin Transformer and, of course, in semantic segmentation, where every pixel must be labelled. However, make up your own mind about the comparisons with the state-of-the art, because you know, like most of the papers nowadays, the baselines are not necessarily tuned to be the strongest. Look at semantic segmentation in Table 3:. The Swin Transformer implementation is compared to the DeiT transformer counterpart, but only in it’s smallest version. A single measurement for one configuration of DeiT is not enough to see how this all behaves when scaling the model, especially when, in terms of number of parameters, DeiT small is even smaller than Swin Tiny- Not really a worthy opponent for Swin-Large here, right? Make up your own mind about this and let us know in the comments what you think. Which vision transformer variant is the one that determined you to leave the ViT model and use another variant (if any)? Ms Coffee Bean would be curious about that. If you liked this content, do not forget to leave a like. to help with the YouTube algorithm, Ms Coffee Bean. I am curious to know if THE YT Algorithm is transformer-based or not. Ms Coffee Bean, Where are you going? I did not end the video yet. Well, I guess it ended now. Okay, bye.'"},"metadata":{}}]},{"cell_type":"code","source":"vie_sub = translate_long(sub)\nvie_sub","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:54.949762Z","iopub.execute_input":"2024-06-03T02:03:54.951538Z","iopub.status.idle":"2024-06-03T02:03:58.252525Z","shell.execute_reply.started":"2024-06-03T02:03:54.951486Z","shell.execute_reply":"2024-06-03T02:03:58.251121Z"},"trusted":true},"execution_count":84,"outputs":[{"execution_count":84,"output_type":"execute_result","data":{"text/plain":"'Xin chào, hôm nay chúng ta đang thảo luận về máy biến áp Swin.Swin đứng ở đây cho các cửa sổ thay đổi và về cơ bản là một biến thể biến áp tầm nhìn, nhưng với cách xử lý hình ảnh phân cấp.Vì vậy, nếu bạn tò mò về Vision Transformer Beast này đã đánh bại nhiều điểm chuẩn, hãy lấy một tách cà phê, bởi vì đã đến lúc nghỉ cà phê AI.Nói về động lực cho máy biến áp Swin, đọc phần này của bản tóm tắt đã kích hoạt tôi một chút.Đó là về các thách thức của người Viking trong việc điều chỉnh máy biến áp từ ngôn ngữ này sang ngôn ngữ khác \"và các tác giả nói rằng chúng\" phát sinh từ sự khác biệt giữa hai lĩnh vực, chẳng hạn như các biến thể lớn trong quy mô của các thực thể trực quan và độ phân giải cao của pixel trong hình ảnh so với các từtrong văn bản ”.Đây là một điều như một nhà nghiên cứu tầm nhìn máy tính để nói.Mọi thứ đều là dữ liệu lớn nếu bạn đủ can đảm.Các từ trong văn bản cũng có thể trở thành quá nhiều nếu người ta muốn xử lý một cuốn tiểu thuyết Dostoyevsky hoàn chỉnh như một điểm dữ liệu duy nhất.Nhưng vâng, điểm được lấy từ các tác giả ở đây rằng có nhiều hình ảnh trên thế giới này hơn tiểu thuyết.Vì vậy, vui nhộn, trong khi các máy biến áp có sự chú ý mở rộng tuyến tính có thể xử lý toàn bộ tiểu thuyết như một chuỗi, không có đủ tiểu thuyết được viết để tạo ra các bộ dữ liệu quan trọng theo cách này.Vì vậy, yeah, các máy biến áp văn bản thường hoạt động với các chuỗi nhỏ hơn và văn bản thường được xử lý ở cấp độ câu.Dù sao, trở lại với máy biến áp Swin.Ở đây dựa trên VIT và để nhớ cách thức hoạt động của máy biến áp tầm nhìn, bạn có thể xem video của chúng tôi về việc này, bởi vì ở đây chúng tôi sẽ đưa nó vào một hạt: hình ảnh được phân tách thành các bản vá pixel 16x16.Sau đó, các bản vá này được chuyển đổi thành các vectơ vá bằng cách chuyển đổi tuyến tính.Các vectơ bản vá này, kết hợp với các nhúng vị trí, được xử lý bởi một máy biến áp theo cách tương tự trong đó các máy biến áp xử lý các vectơ Word, mà chúng ta cũng đã thảo luận trong một video trước đó.Nhưng có một vấn đề với máy biến áp tầm nhìn mà các tác giả ở đây cố gắng giảm bớt với bộ chuyển đổi Swin.Vấn đề có liên quan đến việc trích xuất các bản vá, một bước đặc biệt đối với hình ảnh, không phải là văn bản.Nếu hình ảnh là, hãy để nói rằng, 256x256 pixel, sau đó trích xuất các bản vá 16x16 pixel sẽ dẫn đến 16 bản vá.Do đó, 16 vectơ hình ảnh sẽ tạo thành một chuỗi.Nhưng một hình ảnh của 1920x1920 pixel đã dẫn đến 120 vectơ hình ảnh, điều này vẫn ổn, với GPU lớn hơn và lớn hơn, tất nhiên.Và nếu chúng ta làm điều này để giải quyết các nhiệm vụ trong đó nhìn vào các bản vá 16x16 pixel không quá thô, thì VIT vẫn ổn.Và đây là trường hợp cho các tác vụ theo nghĩa tóm tắt hình ảnh, giống như trường hợp của nó với phân loại hình ảnh, trong đó mục tiêu là dự đoán một nhãn cho toàn bộ hình ảnh.Phân tích hình ảnh thông qua các bản vá lớn không phải là vấn đề ở đây, nhưng có những nhiệm vụ mà người ta thực sự cần thông tin chi tiết ở cấp độ pixel, không phải các bản vá.Một nhiệm vụ như vậy là phân đoạn ngữ nghĩa, trong đó thuật toán cần quyết định cho từng pixel trong hình ảnh mà loại này thuộc về.Trong trường hợp này, các bản vá 16 x 16 pixel là cách lớn.Vì vậy, lý tưởng nhất là chúng tôi muốn xử lý mọi pixel như một mã thông báo, nhưng điều này sẽ nhanh chóng trở nên không khả thi.Ví dụ, hình ảnh 256 by 256 pixel đã yêu cầu độ dài trình tự xử lý máy biến áp trên 63.000 mã thông báo.Một hình ảnh Full HD 1920x1080 sẽ yêu cầu một chuỗi độ dài hơn 2 triệu.Điều này không thể mở rộng, và chúng ta hoàn toàn có thể quên việc mở rộng quá trình xử lý học tập sâu bản địa sang hình ảnh 4K - ai đủ điên rồ để thậm chí muốn làm điều đó, dù sao đi nữa?Vì vậy, bây giờ chúng tôi đã thấy rằng VIT trước tiên chia hình ảnh thành các bản vá để giữ độ dài trình tự trong giới hạn tính toán, nhưng điều này có vấn đề đối với các nhiệm vụ yêu cầu xử lý chi tiết mỗi pixel.Vì vậy, hãy để Lôi nhìn vào cách máy biến áp Swin muốn giải quyết vấn đề này.Máy biến áp Swin vẫn dựa vào các bản vá, nhưng thay vì chọn một kích thước và gắn với nó, máy biến áp Swin trước tiên bắt đầu bằng các bản vá nhỏ cho lớp máy biến áp đầu tiên, sau đó hợp nhất chúng thành các lớp lớn hơn trong các lớp biến áp sâu hơn.Điều này nhắc nhở chúng ta về một cái gì đó MS Coffee Bean, Yeah, về U-Net và Constrolutions.Bây giờ, hãy để không bị phân tâm ở đây.Vì vậy, máy biến áp Swin chụp ảnh và chia hình ảnh thành các bản vá 4x4.Mỗi bản vá vẫn là một hình ảnh màu với ba kênh.Vì vậy, một bản vá có 4x4x3 bằng 48 chiều, sau đó được chuyển đổi tuyến tính thành một chiều C mà bạn chọn.Vì vậy, sự khác biệt duy nhất cho VIT cho đến nay là các bản vá nhỏ hơn.Nhưng những gì về kích thước này C?Và điều đó có nghĩa là gì?Vâng, C xác định công suất hoặc kích thước của mô hình máy biến áp của bạn. Vì vậy, bạn có thể biết rằng có một mô hình văn bản Bert-Base có kích thước 768 cho các biểu diễn vectơ.Vâng, trong trường hợp đó C là 768 .. Ngoài ra còn có Bert lớn với C = 1024 .. C là công suất của mô hình, bởi vì nó xác định kích thước tham số hoặc lượng đơn vị ẩn trong các lớp được kết nối hoàn toàn.Ở đây, chỉ để có ấn tượng về máy biến áp Swin: đối với Swin-Mode, C là 96 và 192 cho Swin-Large.Nhưng chúng ta đã ở đâu tại máy biến áp Swin đã chia hình ảnh thành các bản vá 4 pixel ban đầu và một phép biến đổi tuyến tính chuyển đổi mỗi bản vá thành một vectơ chiều c.Các khối máy biến áp xử lý các vectơ vá này, nhưng không phải với sự chú ý tỷ lệ bậc hai thông thường, mà với sự tự ý dựa trên cửa sổ thay đổi được giới thiệu bởi các tác giả.Đây chỉ là một cái tên lạ mắt khi nói rằng khoảng chú ý bị giới hạn trong các bản vá m (ở đây hai).Vì vậy, bây giờ trong sự chú ý của bản thân, một bản vá không giao tiếp với tất cả các bản vá khác, mà chỉ với các hàng xóm của m.Tôi rất chắc chắn rằng tôi đã thấy cửa sổ này giới hạn sự tự ý trước đây trong một bài báo khác dưới một tên khác, MS Coffee Bean.Bạn có nhớ ở đâu không?Không, ồ, tôi sẽ hỏi khán giả sau đó.Nếu bạn đã thấy sự chú ý này trước đây, hoặc một cái gì đó rất giống với nó, thì xin vui lòng cho chúng tôi biết trong các bình luận nơi nó có thể là một bài báo NLP.OK, trong mọi trường hợp, cửa sổ chú ý hạn chế về cơ bản mô phỏng, hãy nói, hãy nói, mã thông báo bản vá hình ảnh đầu tiên này ở đây- rằng phần còn lại của chuỗi không có trong khu phố M của nó về cơ bản đã biến mất.Điều này có nghĩa là thay vào đó là một tính toán chú ý theo tỷ lệ bậc hai với độ dài trình tự, giờ đây chúng ta có một cái gì đó tuyến tính cho m nhỏ, tuyệt vời.Vì vậy, bây giờ là lúc để di chuyển xa hơn đến lớp tiếp theo trong hệ thống phân cấp.Ở đây, đầu ra của một chuỗi các vectơ vá N một lần nữa là các vectơ n, bởi vì máy biến áp là một bộ điều chỉnh tự động.Bây giờ, đầu ra được hợp nhất bởi một cái gọi là lớp hợp nhất.Điều này kết hợp các vectơ của các nhóm các bản vá lân cận 2x2 (trong hình ảnh, không phải trong chuỗi vì nó được hình dung khá đơn giản ở đây).Vì vậy, từ 4 trong số các vectơ chiều C này, chúng tôi hiện có một vectơ chiều 4xc và điều này được truyền qua một lớp tuyến tính, về cơ bản là một bộ giảm tốc độ tuyến tính từ 4C đến kích thước 2c.Ok, hãy để đơn giản hóa ở đây một chút.Nếu ban đầu chúng tôi có 4 bản vá, bây giờ chúng tôi sẽ có 1 bản vá, nhưng lưu ý rằng biểu diễn ẩn đã được nhân đôi để tăng khả năng nắm bắt thông tin từ một khu vực lớn hơn.Và sau đó một lần nữa toàn bộ quá trình lặp lại.Một mô-đun biến áp Span Span hạn chế đang xử lý đầu ra, và điều này cứ lặp đi lặp lại.Nhưng mỗi lần cửa sổ chú ý được thay đổi theo lớp trước.Vì vậy, nếu ở lớp đầu tiên, sự chú ý được giới hạn ở các vùng lân cận của các vùng này, trong lớp tiếp theo, các vùng được dịch chuyển (như trong tích chập được sảihai.Sau đó, các vectơ vá kết quả một lần nữa được hợp nhất bởi lớp hợp nhất và toàn bộ quy trình phân cấp được lặp lại, tùy thuộc vào số lượng lớp được chọn hoặc cho đến khi không còn hợp nhất nữa.Và điều này về cơ bản là nó.MS Coffee Bean có hai bình luận nữa.Đầu tiên, liên quan đến việc nhúng vị trí cho máy biến áp Swin, chúng ta nên nói rằng, về nguyên tắc, tất cả các loại nhúng vị trí đều được áp dụng, nhưng các tác giả thấy rằng việc nhúng vị trí được thêm trực tiếp vào biểu diễn vectơ của các mã thông báo không hoạt động, vìCũng như sự thiên vị vị trí tương đối trong việc tự ý, một phương pháp rất giống với những gì chúng tôi đã trình bày trong video này.Và thứ hai, máy biến áp Swin tốt như thế nào?Vâng, nó vượt trội so với VIT và DEIT về phân loại hình ảnh, phát hiện đối tượng và phân đoạn ngữ nghĩa.Nó đối tượng nhỏ trong phát hiện đối tượng, nơi chúng ta mong đợi sẽ thấy những cải tiến với máy biến áp Swin và tất nhiên, trong phân đoạn ngữ nghĩa, nơi mọi pixel phải được dán nhãn.Tuy nhiên, quyết định của riêng bạn về sự so sánh với nghệ thuật hiện đại, bởi vì bạn biết, giống như hầu hết các bài báo ngày nay, các đường cơ sở không nhất thiết phải được điều chỉnh mạnh nhất.Nhìn vào phân đoạn ngữ nghĩa trong Bảng 3:.Việc triển khai biến áp Swin được so sánh với đối tác DEIT Transformer, nhưng chỉ trong phiên bản nhỏ nhất của nó.Một phép đo duy nhất cho một cấu hình của DEIT là không đủ để thấy tất cả điều này hoạt động như thế nào khi tỷ lệ mô hình, đặc biệt là khi, về số lượng tham số, DEIT nhỏ thậm chí còn nhỏ hơn cả swin nhỏ- không thực sự là một đối thủ xứng đáng cho swin-largeỞ đây, phải không? Nằm trong suy nghĩ của riêng bạn về điều này và cho chúng tôi biết trong các ý kiến \\u200b\\u200bbạn nghĩ gì.Biến thể máy biến áp tầm nhìn nào là biến thể quyết định bạn rời khỏi mô hình VIT và sử dụng một biến thể khác (nếu có)?MS Coffee Bean sẽ tò mò về điều đó.Nếu bạn thích nội dung này, đừng quên rời đi.Để giúp thuật toán YouTube, MS Coffee Bean.Tôi tò mò muốn biết rằng thuật toán YT có dựa trên máy biến áp hay không.MS Coffee Bean, bạn đang đi đâu?Tôi chưa kết thúc video.Vâng, tôi đoán nó đã kết thúc ngay bây giờ.Vâng, tạm biệt.'"},"metadata":{}}]},{"cell_type":"code","source":"vie_sub = processed(vie_sub)\nvie_sub","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:58.253833Z","iopub.execute_input":"2024-06-03T02:03:58.254216Z","iopub.status.idle":"2024-06-03T02:03:58.262811Z","shell.execute_reply.started":"2024-06-03T02:03:58.254188Z","shell.execute_reply":"2024-06-03T02:03:58.261331Z"},"trusted":true},"execution_count":85,"outputs":[{"execution_count":85,"output_type":"execute_result","data":{"text/plain":"'xin chào, hôm nay chúng ta đang thảo luận về máy biến áp swin.swin đứng ở đây cho các cửa sổ thay đổi và về cơ bản là một biến thể biến áp tầm nhìn, nhưng với cách xử lý hình ảnh phân cấp.vì vậy, nếu bạn tò mò về vision transformer beast này đã đánh bại nhiều điểm chuẩn, hãy lấy một tách cà phê, bởi vì đã đến lúc nghỉ cà phê ai.nói về động lực cho máy biến áp swin, đọc phần này của bản tóm tắt đã kích hoạt tôi một chút.đó là về các thách thức của người viking trong việc điều chỉnh máy biến áp từ ngôn ngữ này sang ngôn ngữ khác \"và các tác giả nói rằng chúng\" phát sinh từ sự khác biệt giữa hai lĩnh vực, chẳng hạn như các biến thể lớn trong quy mô của các thực thể trực quan và độ phân giải cao của pixel trong hình ảnh so với các từtrong văn bản ”.đây là một điều như một nhà nghiên cứu tầm nhìn máy tính để nói.mọi thứ đều là dữ liệu lớn nếu bạn đủ can đảm.các từ trong văn bản cũng có thể trở thành quá nhiều nếu người ta muốn xử lý một cuốn tiểu thuyết dostoyevsky hoàn chỉnh như một điểm dữ liệu duy nhất.nhưng vâng, điểm được lấy từ các tác giả ở đây rằng có nhiều hình ảnh trên thế giới này hơn tiểu thuyết.vì vậy, vui nhộn, trong khi các máy biến áp có sự chú ý mở rộng tuyến tính có thể xử lý toàn bộ tiểu thuyết như một chuỗi, không có đủ tiểu thuyết được viết để tạo ra các bộ dữ liệu quan trọng theo cách này.vì vậy, yeah, các máy biến áp văn bản thường hoạt động với các chuỗi nhỏ hơn và văn bản thường được xử lý ở cấp độ câu.dù sao, trở lại với máy biến áp swin.ở đây dựa trên vit và để nhớ cách thức hoạt động của máy biến áp tầm nhìn, bạn có thể xem video của chúng tôi về việc này, bởi vì ở đây chúng tôi sẽ đưa nó vào một hạt: hình ảnh được phân tách thành các bản vá pixel 16x16.sau đó, các bản vá này được chuyển đổi thành các vectơ vá bằng cách chuyển đổi tuyến tính.các vectơ bản vá này, kết hợp với các nhúng vị trí, được xử lý bởi một máy biến áp theo cách tương tự trong đó các máy biến áp xử lý các vectơ word, mà chúng ta cũng đã thảo luận trong một video trước đó.nhưng có một vấn đề với máy biến áp tầm nhìn mà các tác giả ở đây cố gắng giảm bớt với bộ chuyển đổi swin.vấn đề có liên quan đến việc trích xuất các bản vá, một bước đặc biệt đối với hình ảnh, không phải là văn bản.nếu hình ảnh là, hãy để nói rằng, 256x256 pixel, sau đó trích xuất các bản vá 16x16 pixel sẽ dẫn đến 16 bản vá.do đó, 16 vectơ hình ảnh sẽ tạo thành một chuỗi.nhưng một hình ảnh của 1920x1920 pixel đã dẫn đến 120 vectơ hình ảnh, điều này vẫn ổn, với gpu lớn hơn và lớn hơn, tất nhiên.và nếu chúng ta làm điều này để giải quyết các nhiệm vụ trong đó nhìn vào các bản vá 16x16 pixel không quá thô, thì vit vẫn ổn.và đây là trường hợp cho các tác vụ theo nghĩa tóm tắt hình ảnh, giống như trường hợp của nó với phân loại hình ảnh, trong đó mục tiêu là dự đoán một nhãn cho toàn bộ hình ảnh.phân tích hình ảnh thông qua các bản vá lớn không phải là vấn đề ở đây, nhưng có những nhiệm vụ mà người ta thực sự cần thông tin chi tiết ở cấp độ pixel, không phải các bản vá.một nhiệm vụ như vậy là phân đoạn ngữ nghĩa, trong đó thuật toán cần quyết định cho từng pixel trong hình ảnh mà loại này thuộc về.trong trường hợp này, các bản vá 16 x 16 pixel là cách lớn.vì vậy, lý tưởng nhất là chúng tôi muốn xử lý mọi pixel như một mã thông báo, nhưng điều này sẽ nhanh chóng trở nên không khả thi.ví dụ, hình ảnh 256 by 256 pixel đã yêu cầu độ dài trình tự xử lý máy biến áp trên 63.000 mã thông báo.một hình ảnh full hd 1920x1080 sẽ yêu cầu một chuỗi độ dài hơn 2 triệu.điều này không thể mở rộng, và chúng ta hoàn toàn có thể quên việc mở rộng quá trình xử lý học tập sâu bản địa sang hình ảnh 4k - ai đủ điên rồ để thậm chí muốn làm điều đó, dù sao đi nữa?vì vậy, bây giờ chúng tôi đã thấy rằng vit trước tiên chia hình ảnh thành các bản vá để giữ độ dài trình tự trong giới hạn tính toán, nhưng điều này có vấn đề đối với các nhiệm vụ yêu cầu xử lý chi tiết mỗi pixel.vì vậy, hãy để lôi nhìn vào cách máy biến áp swin muốn giải quyết vấn đề này.máy biến áp swin vẫn dựa vào các bản vá, nhưng thay vì chọn một kích thước và gắn với nó, máy biến áp swin trước tiên bắt đầu bằng các bản vá nhỏ cho lớp máy biến áp đầu tiên, sau đó hợp nhất chúng thành các lớp lớn hơn trong các lớp biến áp sâu hơn.điều này nhắc nhở chúng ta về một cái gì đó ms coffee bean, yeah, về u-net và constrolutions.bây giờ, hãy để không bị phân tâm ở đây.vì vậy, máy biến áp swin chụp ảnh và chia hình ảnh thành các bản vá 4x4.mỗi bản vá vẫn là một hình ảnh màu với ba kênh.vì vậy, một bản vá có 4x4x3 bằng 48 chiều, sau đó được chuyển đổi tuyến tính thành một chiều c mà bạn chọn.vì vậy, sự khác biệt duy nhất cho vit cho đến nay là các bản vá nhỏ hơn.nhưng những gì về kích thước này c?và điều đó có nghĩa là gì?vâng, c xác định công suất hoặc kích thước của mô hình máy biến áp của bạn. vì vậy, bạn có thể biết rằng có một mô hình văn bản bert-base có kích thước 768 cho các biểu diễn vectơ.vâng, trong trường hợp đó c là 768 .. ngoài ra còn có bert lớn với c = 1024 .. c là công suất của mô hình, bởi vì nó xác định kích thước tham số hoặc lượng đơn vị ẩn trong các lớp được kết nối hoàn toàn.ở đây, chỉ để có ấn tượng về máy biến áp swin: đối với swin-mode, c là 96 và 192 cho swin-large.nhưng chúng ta đã ở đâu tại máy biến áp swin đã chia hình ảnh thành các bản vá 4 pixel ban đầu và một phép biến đổi tuyến tính chuyển đổi mỗi bản vá thành một vectơ chiều c.các khối máy biến áp xử lý các vectơ vá này, nhưng không phải với sự chú ý tỷ lệ bậc hai thông thường, mà với sự tự ý dựa trên cửa sổ thay đổi được giới thiệu bởi các tác giả.đây chỉ là một cái tên lạ mắt khi nói rằng khoảng chú ý bị giới hạn trong các bản vá m (ở đây hai).vì vậy, bây giờ trong sự chú ý của bản thân, một bản vá không giao tiếp với tất cả các bản vá khác, mà chỉ với các hàng xóm của m.tôi rất chắc chắn rằng tôi đã thấy cửa sổ này giới hạn sự tự ý trước đây trong một bài báo khác dưới một tên khác, ms coffee bean.bạn có nhớ ở đâu không?không, ồ, tôi sẽ hỏi khán giả sau đó.nếu bạn đã thấy sự chú ý này trước đây, hoặc một cái gì đó rất giống với nó, thì xin vui lòng cho chúng tôi biết trong các bình luận nơi nó có thể là một bài báo nlp.ok, trong mọi trường hợp, cửa sổ chú ý hạn chế về cơ bản mô phỏng, hãy nói, hãy nói, mã thông báo bản vá hình ảnh đầu tiên này ở đây- rằng phần còn lại của chuỗi không có trong khu phố m của nó về cơ bản đã biến mất.điều này có nghĩa là thay vào đó là một tính toán chú ý theo tỷ lệ bậc hai với độ dài trình tự, giờ đây chúng ta có một cái gì đó tuyến tính cho m nhỏ, tuyệt vời.vì vậy, bây giờ là lúc để di chuyển xa hơn đến lớp tiếp theo trong hệ thống phân cấp.ở đây, đầu ra của một chuỗi các vectơ vá n một lần nữa là các vectơ n, bởi vì máy biến áp là một bộ điều chỉnh tự động.bây giờ, đầu ra được hợp nhất bởi một cái gọi là lớp hợp nhất.điều này kết hợp các vectơ của các nhóm các bản vá lân cận 2x2 (trong hình ảnh, không phải trong chuỗi vì nó được hình dung khá đơn giản ở đây).vì vậy, từ 4 trong số các vectơ chiều c này, chúng tôi hiện có một vectơ chiều 4xc và điều này được truyền qua một lớp tuyến tính, về cơ bản là một bộ giảm tốc độ tuyến tính từ 4c đến kích thước 2c.ok, hãy để đơn giản hóa ở đây một chút.nếu ban đầu chúng tôi có 4 bản vá, bây giờ chúng tôi sẽ có 1 bản vá, nhưng lưu ý rằng biểu diễn ẩn đã được nhân đôi để tăng khả năng nắm bắt thông tin từ một khu vực lớn hơn.và sau đó một lần nữa toàn bộ quá trình lặp lại.một mô-đun biến áp span span hạn chế đang xử lý đầu ra, và điều này cứ lặp đi lặp lại.nhưng mỗi lần cửa sổ chú ý được thay đổi theo lớp trước.vì vậy, nếu ở lớp đầu tiên, sự chú ý được giới hạn ở các vùng lân cận của các vùng này, trong lớp tiếp theo, các vùng được dịch chuyển (như trong tích chập được sảihai.sau đó, các vectơ vá kết quả một lần nữa được hợp nhất bởi lớp hợp nhất và toàn bộ quy trình phân cấp được lặp lại, tùy thuộc vào số lượng lớp được chọn hoặc cho đến khi không còn hợp nhất nữa.và điều này về cơ bản là nó.ms coffee bean có hai bình luận nữa.đầu tiên, liên quan đến việc nhúng vị trí cho máy biến áp swin, chúng ta nên nói rằng, về nguyên tắc, tất cả các loại nhúng vị trí đều được áp dụng, nhưng các tác giả thấy rằng việc nhúng vị trí được thêm trực tiếp vào biểu diễn vectơ của các mã thông báo không hoạt động, vìcũng như sự thiên vị vị trí tương đối trong việc tự ý, một phương pháp rất giống với những gì chúng tôi đã trình bày trong video này.và thứ hai, máy biến áp swin tốt như thế nào?vâng, nó vượt trội so với vit và deit về phân loại hình ảnh, phát hiện đối tượng và phân đoạn ngữ nghĩa.nó đối tượng nhỏ trong phát hiện đối tượng, nơi chúng ta mong đợi sẽ thấy những cải tiến với máy biến áp swin và tất nhiên, trong phân đoạn ngữ nghĩa, nơi mọi pixel phải được dán nhãn.tuy nhiên, quyết định của riêng bạn về sự so sánh với nghệ thuật hiện đại, bởi vì bạn biết, giống như hầu hết các bài báo ngày nay, các đường cơ sở không nhất thiết phải được điều chỉnh mạnh nhất.nhìn vào phân đoạn ngữ nghĩa trong bảng 3:.việc triển khai biến áp swin được so sánh với đối tác deit transformer, nhưng chỉ trong phiên bản nhỏ nhất của nó.một phép đo duy nhất cho một cấu hình của deit là không đủ để thấy tất cả điều này hoạt động như thế nào khi tỷ lệ mô hình, đặc biệt là khi, về số lượng tham số, deit nhỏ thậm chí còn nhỏ hơn cả swin nhỏ- không thực sự là một đối thủ xứng đáng cho swin-largeở đây, phải không? nằm trong suy nghĩ của riêng bạn về điều này và cho chúng tôi biết trong các ý kiến \\u200b\\u200bbạn nghĩ gì.biến thể máy biến áp tầm nhìn nào là biến thể quyết định bạn rời khỏi mô hình vit và sử dụng một biến thể khác (nếu có)?ms coffee bean sẽ tò mò về điều đó.nếu bạn thích nội dung này, đừng quên rời đi.để giúp thuật toán youtube, ms coffee bean.tôi tò mò muốn biết rằng thuật toán yt có dựa trên máy biến áp hay không.ms coffee bean, bạn đang đi đâu?tôi chưa kết thúc video.vâng, tôi đoán nó đã kết thúc ngay bây giờ.vâng, tạm biệt.'"},"metadata":{}}]},{"cell_type":"code","source":"chunks = split_into_chunks(vie_sub, 700, 3)\nsum_para = []\nfor i in chunks:\n    tmp = summarize(i, model_aug, tokenizer, num_beams=4)\n    sum_para.append(tmp)\nsuma = ''.join(sum_para)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:03:58.264628Z","iopub.execute_input":"2024-06-03T02:03:58.265102Z","iopub.status.idle":"2024-06-03T02:05:04.423727Z","shell.execute_reply.started":"2024-06-03T02:03:58.265053Z","shell.execute_reply":"2024-06-03T02:05:04.421986Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"suma = post_processing(suma)\nsuma","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:05:04.425451Z","iopub.execute_input":"2024-06-03T02:05:04.425835Z","iopub.status.idle":"2024-06-03T02:05:04.433806Z","shell.execute_reply.started":"2024-06-03T02:05:04.425804Z","shell.execute_reply":"2024-06-03T02:05:04.432476Z"},"trusted":true},"execution_count":87,"outputs":[{"execution_count":87,"output_type":"execute_result","data":{"text/plain":"'Tóm tắt về máy biến áp swin: máy biến áp tầm nhìn xử lý hình ảnh phân cấp xử lý hình ảnh phân cấp với các bản vá nhỏ hơn và độ phân giải cao hơn máy biến áp văn bản. Tóm tắt về máy biến áp swin: máy biến áp tầm nhìn xử lý hình ảnh phân cấp xử lý hình ảnh phân cấp với các bản vá nhỏ hơn và độ phân giải cao hơn máy biến áp văn bản. Tóm tắt về máy biến áp swin: máy biến áp tầm nhìn xử lý hình ảnh phân cấp xử lý hình ảnh phân cấp với các bản vá nhỏ hơn và độ phân giải cao hơn máy biến áp văn bản. Tóm tắt về máy biến áp swin: máy biến áp tầm nhìn xử lý hình ảnh phân cấp xử lý hình ảnh phân cấp với các bản vá nhỏ hơn và độ phân giải cao hơn máy biến áp văn bản. Máy biến áp swin xử lý các vectơ vá tỷ lệ bậc hai bằng cách chia hình ảnh thành các vectơ vá 2x2 thành các vectơ vá 2x2. '"},"metadata":{}}]},{"cell_type":"code","source":"display(suma)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:05:04.435431Z","iopub.execute_input":"2024-06-03T02:05:04.435799Z","iopub.status.idle":"2024-06-03T02:05:04.449520Z","shell.execute_reply.started":"2024-06-03T02:05:04.435764Z","shell.execute_reply":"2024-06-03T02:05:04.448233Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"• Tóm tắt về máy biến áp swin: máy biến áp tầm nhìn xử lý hình ảnh phân cấp xử lý hình ảnh phân cấp với các bản vá nhỏ hơn và độ phân giải cao hơn máy biến áp văn bản.\n• Máy biến áp swin xử lý các vectơ vá tỷ lệ bậc hai bằng cách chia hình ảnh thành các vectơ vá 2x2 thành các vectơ vá 2x2.\n","output_type":"stream"}]},{"cell_type":"code","source":"youtube_video = \"https://www.youtube.com/watch?v=SndHALawoag\"\nvideo_id = youtube_video.split(\"=\")[1]\nfrom IPython.display import YouTubeVideo\nYouTubeVideo(video_id)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:05:04.451201Z","iopub.execute_input":"2024-06-03T02:05:04.451602Z","iopub.status.idle":"2024-06-03T02:05:04.497059Z","shell.execute_reply.started":"2024-06-03T02:05:04.451566Z","shell.execute_reply":"2024-06-03T02:05:04.495958Z"},"trusted":true},"execution_count":89,"outputs":[{"execution_count":89,"output_type":"execute_result","data":{"text/plain":"<IPython.lib.display.YouTubeVideo at 0x7dfc6d371e40>","text/html":"\n        <iframe\n            width=\"400\"\n            height=\"300\"\n            src=\"https://www.youtube.com/embed/SndHALawoag\"\n            frameborder=\"0\"\n            allowfullscreen\n            \n        ></iframe>\n        ","image/jpeg":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pipeline('https://www.youtube.com/watch?v=qAwZdMIum0E',model_aug, tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-06-03T02:45:00.715075Z","iopub.execute_input":"2024-06-03T02:45:00.716819Z","iopub.status.idle":"2024-06-03T02:48:45.624903Z","shell.execute_reply.started":"2024-06-03T02:45:00.716762Z","shell.execute_reply":"2024-06-03T02:48:45.623508Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"Time elapsed for get_subtitles: 50.309062004089355\nTime elapsed for processing subtitles: 14.020203828811646\nTime elapsed for summarization: 160.56814074516296\nTime elapsed for post processing: 0.000152587890625\n• Để chuẩn bị cho bài kiểm tra tiếng anh paper one hãy chuẩn bị trước bằng cách đọc kỹ các câu hỏi và giải thích từ vựng rõ ràng.\n• Để tóm tắt câu hỏi sinh viên cần viết ngắn gọn và chính xác sử dụng dấu hiệu diễn ngôn phù hợp và bắt đầu với câu hỏi thứ nhất và thứ hai.\n• Bắt đầu với câu hỏi thứ nhất và thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai.\n• Bắt đầu với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ hai và cuối.\n• Bắt đầu với câu hỏi thứ nhất và thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ hai.\n• Khi viết một đoạn văn hãy xác định từ hoặc cụm từ gợi ý ý tưởng và sử dụng từ đồng nghĩa để thay thế các từ được nhấn mạnh.\n• Để xây dựng câu chủ đề hãy chọn hình ảnh gợi ý và sử dụng các thuật ngữ cụ thể như danh từ tính từ hoặc danh từ.\n• Bắt đầu câu thứ nhất bằng hình ảnh chèn trích dẫn giải thích ý nghĩa của từ và sử dụng các thuật ngữ cụ thể như danh từ tính từ hoặc danh từ.\n• Bắt đầu câu thứ hai bằng hình ảnh giải thích ý nghĩa của từ và sử dụng các thuật ngữ cụ thể như danh từ tính từ hoặc danh từ.\n• Đánh dấu diễn ngôn bằng dấu chấm lửng và lặp lại cấu trúc câu.\n• Sử dụng thông tin cung cấp sau dấu chấm lửng để tập trung xây dựng đoạn văn.\n• Tóm tắt nội dung câu hỏi bullet point: ý tưởng rõ ràng ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn.\n• Tóm tắt nội dung câu hỏi bullet point đầu tiên bullet point thứ hai bullet point thứ hai bullet point thứ ba: ý tưởng rõ ràng ý tưởng hấp dẫn mục đích khán giả mục đích khán giả và hình thức.\n• Tóm tắt nội dung câu hỏi bullet point đầu tiên và thứ hai để tạo ra tác phẩm phi hư cấu hiệu quả.\n• Tạo văn bản phi hư cấu hiệu quả thông qua phong cách tính năng tính năng và mục đích sử dụng.\n• Để viết một bài báo hiệu quả hãy sử dụng ngôn ngữ trò chuyện thành ngữ và đặt câu hỏi cụ thể cho từng loại văn bản.\n","output_type":"stream"},{"execution_count":94,"output_type":"execute_result","data":{"text/plain":"'Để chuẩn bị cho bài kiểm tra tiếng anh paper one hãy chuẩn bị trước bằng cách đọc kỹ các câu hỏi và giải thích từ vựng rõ ràng. Để chuẩn bị cho bài kiểm tra tiếng anh paper one hãy chuẩn bị trước bằng cách đọc kỹ các câu hỏi và giải thích từ vựng rõ ràng. Để chuẩn bị cho bài kiểm tra tiếng anh paper one hãy chuẩn bị trước bằng cách đọc kỹ các câu hỏi và giải thích từ vựng rõ ràng. Để tóm tắt câu hỏi sinh viên cần viết ngắn gọn và chính xác sử dụng dấu hiệu diễn ngôn phù hợp và bắt đầu với câu hỏi thứ nhất và thứ hai. Bắt đầu với câu hỏi thứ nhất và thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai. Bắt đầu với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ hai và cuối. Bắt đầu với câu hỏi thứ nhất và thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ nhất và câu hỏi thứ hai với câu hỏi thứ hai. Khi viết một đoạn văn hãy xác định từ hoặc cụm từ gợi ý ý tưởng và sử dụng từ đồng nghĩa để thay thế các từ được nhấn mạnh. Để xây dựng câu chủ đề hãy chọn hình ảnh gợi ý và sử dụng các thuật ngữ cụ thể như danh từ tính từ hoặc danh từ. Bắt đầu câu thứ nhất bằng hình ảnh chèn trích dẫn giải thích ý nghĩa của từ và sử dụng các thuật ngữ cụ thể như danh từ tính từ hoặc danh từ. Bắt đầu câu thứ hai bằng hình ảnh giải thích ý nghĩa của từ và sử dụng các thuật ngữ cụ thể như danh từ tính từ hoặc danh từ. Đánh dấu diễn ngôn bằng dấu chấm lửng và lặp lại cấu trúc câu. Sử dụng thông tin cung cấp sau dấu chấm lửng để tập trung xây dựng đoạn văn. Tóm tắt nội dung câu hỏi bullet point: ý tưởng rõ ràng ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn bullet point: ý tưởng hấp dẫn. Tóm tắt nội dung câu hỏi bullet point đầu tiên bullet point thứ hai bullet point thứ hai bullet point thứ ba: ý tưởng rõ ràng ý tưởng hấp dẫn mục đích khán giả mục đích khán giả và hình thức. Tóm tắt nội dung câu hỏi bullet point đầu tiên và thứ hai để tạo ra tác phẩm phi hư cấu hiệu quả. Tạo văn bản phi hư cấu hiệu quả thông qua phong cách tính năng tính năng và mục đích sử dụng. Để viết một bài báo hiệu quả hãy sử dụng ngôn ngữ trò chuyện thành ngữ và đặt câu hỏi cụ thể cho từng loại văn bản. '"},"metadata":{}}]}]}